{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Group 1:\n",
        "- Olga Pendleton (labeled data, built models)\n",
        "- Amer Hot (labeled data, built models)\n",
        "- Jason Paragallo (labeled data, built models)\n",
        "- Justin Lucci (labeled data, built models)"
      ],
      "metadata": {
        "id": "edonBGLJjpJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **'Ove' Gloves**"
      ],
      "metadata": {
        "id": "cM3K7OMunGDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing reguired packages.\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.metrics import log_loss\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "import tensorflow as tf\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import numpy as np\n",
        "from numpy import sqrt\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import f1_score\n",
        "from numpy import arange\n",
        "from sklearn.feature_selection import SelectKBest, chi2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeFd_lCV85TB",
        "outputId": "9cedd332-fc7b-488e-8373-8e3b1b685055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "_-UvxLQom7vN",
        "outputId": "3cdf39f7-785c-48de-9430-6755ad642741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  review_date             handle  rating helpfulness_rating  Amer label  \\\n",
              "0   24-Mar-23          Lynette51     5.0                NaN           0   \n",
              "1   23-Mar-23           J. Young     5.0                NaN           0   \n",
              "2   22-Mar-23  Denise Lynn Wells     5.0                NaN           0   \n",
              "3   20-Mar-23                J J     5.0                NaN           0   \n",
              "4   18-Mar-23             Mrs. B     5.0                NaN           0   \n",
              "\n",
              "   Olga label  Jason label  Justin label  Final label  \\\n",
              "0           0            0           NaN            0   \n",
              "1           0            0           NaN            0   \n",
              "2           0            0           NaN            0   \n",
              "3           0            0           NaN            0   \n",
              "4           0            0           NaN            0   \n",
              "\n",
              "                                              review  \n",
              "0                                      Great product  \n",
              "1  Replaced an older pair with the new ones after...  \n",
              "2  The gloves have more flexibility than mitts or...  \n",
              "3  I bought these to replace worn-out greasy glov...  \n",
              "4  These are so great- they protect you from the ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6048a1a3-da08-4da1-8ec0-6c06fd235226\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_date</th>\n",
              "      <th>handle</th>\n",
              "      <th>rating</th>\n",
              "      <th>helpfulness_rating</th>\n",
              "      <th>Amer label</th>\n",
              "      <th>Olga label</th>\n",
              "      <th>Jason label</th>\n",
              "      <th>Justin label</th>\n",
              "      <th>Final label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24-Mar-23</td>\n",
              "      <td>Lynette51</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Great product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23-Mar-23</td>\n",
              "      <td>J. Young</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Replaced an older pair with the new ones after...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22-Mar-23</td>\n",
              "      <td>Denise Lynn Wells</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>The gloves have more flexibility than mitts or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20-Mar-23</td>\n",
              "      <td>J J</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>I bought these to replace worn-out greasy glov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18-Mar-23</td>\n",
              "      <td>Mrs. B</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>These are so great- they protect you from the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6048a1a3-da08-4da1-8ec0-6c06fd235226')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6048a1a3-da08-4da1-8ec0-6c06fd235226 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6048a1a3-da08-4da1-8ec0-6c06fd235226');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Reading the dataset.\n",
        "ove = pd.read_csv('Ove_label.csv')\n",
        "ove.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ove.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu-Wy_tagdqX",
        "outputId": "6658b8af-21f3-4d5d-85d4-da2a9caa02e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 851 entries, 0 to 850\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   review_date         851 non-null    object \n",
            " 1   handle              850 non-null    object \n",
            " 2   rating              836 non-null    float64\n",
            " 3   helpfulness_rating  90 non-null     object \n",
            " 4   Amer label          851 non-null    int64  \n",
            " 5   Olga label          851 non-null    int64  \n",
            " 6   Jason label         851 non-null    int64  \n",
            " 7   Justin label        0 non-null      float64\n",
            " 8   Final label         851 non-null    int64  \n",
            " 9   review              851 non-null    object \n",
            "dtypes: float64(2), int64(4), object(4)\n",
            "memory usage: 66.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HwacjVuoaCB",
        "outputId": "bf16e064-b9c7-4d99-ea2e-8ed61a1b2372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(851, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has 851 rows and 10 columns. Each row represents a review for a given product. "
      ],
      "metadata": {
        "id": "atbZcNQeofZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting all values in \"Final Label\" column.\n",
        "print(ove['Final label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJeuGYyzqo00",
        "outputId": "1a192363-4980-44b3-a018-c886512126fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    803\n",
            "1     48\n",
            "Name: Final label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating persantage of values in the 'Final label' column.\n",
        "print(ove['Final label'].value_counts(normalize = True).mul(100).round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08AvdbnakRvi",
        "outputId": "e0368e8e-93c0-4137-8d13-15aa3db15f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    94.36\n",
            "1     5.64\n",
            "Name: Final label, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Final label' column has values 0, 1. They represent:\n",
        "- Not counterfeit product as 0, \n",
        "- Counterfeit product as 1, \n",
        "\n",
        "The dataset has:\n",
        "- Not counterfeit product reviews: 803 (94.36%)\n",
        "- Counterfeit product reviews: 48 (5.64%)"
      ],
      "metadata": {
        "id": "1uu5DSgyq60r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping columns that are not useful.\n",
        "ove.drop(columns = ['review_date','handle','helpfulness_rating', 'Amer label', 'Olga label', 'Jason label', 'Justin label'], inplace = True)\n",
        "ove.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "55to0j-ZpccO",
        "outputId": "aadcd2e7-e93a-4979-d1be-13a4e1de192a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  Final label                                             review\n",
              "0     5.0            0                                      Great product\n",
              "1     5.0            0  Replaced an older pair with the new ones after...\n",
              "2     5.0            0  The gloves have more flexibility than mitts or...\n",
              "3     5.0            0  I bought these to replace worn-out greasy glov...\n",
              "4     5.0            0  These are so great- they protect you from the ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1af906e-3bda-4214-a8f4-7466056fc696\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>Final label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Great product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Replaced an older pair with the new ones after...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>The gloves have more flexibility than mitts or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>I bought these to replace worn-out greasy glov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>These are so great- they protect you from the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1af906e-3bda-4214-a8f4-7466056fc696')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1af906e-3bda-4214-a8f4-7466056fc696 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1af906e-3bda-4214-a8f4-7466056fc696');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pre-process data as appropriate (10 pts.)\n",
        "# Printing stopwords.\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzSx74enpN4U",
        "outputId": "8fa41222-7657-4cba-c3cf-8bae08554e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function for preprocessing reviews.\n",
        "def review_preprocess(t):\n",
        "    # Converting all words to lower case.\n",
        "    clean_r = t.lower()\n",
        "    # Removing punctuations.\n",
        "    clean_r = [char for char in clean_r if char not in string.punctuation]\n",
        "    clean_r = ''.join(clean_r)\n",
        "    # Removing numbers.\n",
        "    clean_r = re.sub(\"\\d\", \"\", clean_r)\n",
        "    # Removing stopwords.\n",
        "    clean_r = [word for word in clean_r.split() if word not in stopwords.words('english')]\n",
        "    clean_r = ' '.join(clean_r)\n",
        "    return clean_r"
      ],
      "metadata": {
        "id": "RSu-G-7tsDdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the function to the column in DataFrame.\n",
        "ove['review'] = ove['review'].apply(review_preprocess)\n",
        "ove.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IrLet4VYsqfe",
        "outputId": "303db0bf-87b3-40d9-f579-09c2b30533e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  Final label                                             review\n",
              "0     5.0            0                                      great product\n",
              "1     5.0            0  replaced older pair new ones many years didn’t...\n",
              "2     5.0            0           gloves flexibility mitts flat potholders\n",
              "3     5.0            0  bought replace wornout greasy gloves last cent...\n",
              "4     5.0            0  great protect heat right oven doesnt seem like..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63ded428-7a7f-4593-92ea-48ea18b3ae68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>Final label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>great product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>replaced older pair new ones many years didn’t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>gloves flexibility mitts flat potholders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>bought replace wornout greasy gloves last cent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>great protect heat right oven doesnt seem like...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63ded428-7a7f-4593-92ea-48ea18b3ae68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63ded428-7a7f-4593-92ea-48ea18b3ae68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63ded428-7a7f-4593-92ea-48ea18b3ae68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the corpus using TFIDF.\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "def tokenize_and_stem(text):\n",
        "    # First tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # Filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems"
      ],
      "metadata": {
        "id": "3mjt1LBM9BJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into training and testing.\n",
        "X_o = ove['review']\n",
        "y_o = ove['Final label']\n",
        "\n",
        "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(X_o, y_o, test_size = 0.33, random_state = 101)"
      ],
      "metadata": {
        "id": "GMp5xUpJ10lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Build Naive Bayes and a sequential model with sentence embedding (300 dimensions) (10 pts.)\n",
        "# 3. Assess model performance, pick one metric to compare model performance and explain your metric choice. (10 pts.)\n",
        "# G-means.\n",
        "# Listing the models that will be built.\n",
        "names = [\"Naive Bayes\", \"Logistic Regression\", \"Decision Tree\", \"Boosted Tree\", \"Random Forest\", \"SVM\"]\n",
        "\n",
        "# Defining the corresponding list of classifiers, setting parameters for each model.\n",
        "classifiers = [MultinomialNB(),\n",
        "               LogisticRegression(),\n",
        "               DecisionTreeClassifier(max_depth = 5),\n",
        "               AdaBoostClassifier(), \n",
        "               RandomForestClassifier(max_depth = 5, n_estimators = 10),\n",
        "               SVC(probability = True), \n",
        "               ]\n",
        "\n",
        "# Creating a dictionary to store the optimal thresholds for each model.\n",
        "thresholds = {}\n",
        "\n",
        "# Fitting each classifier to the training set, making predictions on the test set,\n",
        "# evaluating performance, and finding the optimal threshold for each model.\n",
        "for name, clf in zip(names, classifiers):\n",
        "    clf_pipe = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_df = 0.9, max_features = 5000,\n",
        "                                  min_df = 0.1,\n",
        "                                  use_idf = True, tokenizer = tokenize_and_stem, ngram_range = (1, 3))), \n",
        "        (name, clf)\n",
        "    ])\n",
        "  \n",
        "    clf_pipe.fit(X_train_o, y_train_o)\n",
        "\n",
        "    pred_prob = clf_pipe.predict_proba(X_test_o)[:, 1]\n",
        "    fpr, tpr, thresholds_ = roc_curve(y_test_o, pred_prob)\n",
        "\n",
        "    # Computing the G-mean for each threshold.\n",
        "    g_mean = []\n",
        "    for thresh in thresholds_:\n",
        "        pred = (pred_prob >= thresh).astype(int)\n",
        "        g_mean.append(geometric_mean_score(y_test_o, pred))\n",
        "\n",
        "    # Choosing the threshold that maximizes the G-mean.\n",
        "    optimal_idx = np.argmax(g_mean)\n",
        "    optimal_threshold = thresholds_[optimal_idx]\n",
        "\n",
        "    # Storing the optimal threshold in the dictionary.\n",
        "    thresholds[name] = optimal_threshold\n",
        "\n",
        "    # Making predictions using the optimal threshold.\n",
        "    pred = (pred_prob >= optimal_threshold).astype(int)\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test_o, pred_prob)\n",
        "    log_loss_val = log_loss(y_test_o, pred_prob)\n",
        "    g_mean_val = geometric_mean_score(y_test_o, pred)\n",
        "\n",
        "    target_names = ['Not counterfeit product', 'Counterfeit product']\n",
        "\n",
        "    print('\\n\\n', name, '\\n\\n')\n",
        "    print(classification_report(y_test_o, pred, target_names = target_names))\n",
        "    print('ROC AUC: ', round(roc_auc, 2))\n",
        "    print('Log loss: ', round(log_loss_val, 2))\n",
        "    print('G-mean: ', round(g_mean_val, 2))\n",
        "    print('Optimal threshold: ', round(optimal_threshold, 2))\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFyZ4hbUPRP9",
        "outputId": "84b9845a-77f4-4a39-83a5-3403b1318351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Naive Bayes \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.99      0.81      0.89       262\n",
            "    Counterfeit product       0.24      0.84      0.37        19\n",
            "\n",
            "               accuracy                           0.81       281\n",
            "              macro avg       0.61      0.82      0.63       281\n",
            "           weighted avg       0.94      0.81      0.85       281\n",
            "\n",
            "ROC AUC:  0.88\n",
            "Log loss:  0.2\n",
            "G-mean:  0.82\n",
            "Optimal threshold:  0.06\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Logistic Regression \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.98      0.85      0.91       262\n",
            "    Counterfeit product       0.27      0.79      0.41        19\n",
            "\n",
            "               accuracy                           0.84       281\n",
            "              macro avg       0.63      0.82      0.66       281\n",
            "           weighted avg       0.93      0.84      0.88       281\n",
            "\n",
            "ROC AUC:  0.89\n",
            "Log loss:  0.18\n",
            "G-mean:  0.82\n",
            "Optimal threshold:  0.08\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Decision Tree \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.95      0.85      0.90       262\n",
            "    Counterfeit product       0.17      0.42      0.24        19\n",
            "\n",
            "               accuracy                           0.82       281\n",
            "              macro avg       0.56      0.63      0.57       281\n",
            "           weighted avg       0.90      0.82      0.85       281\n",
            "\n",
            "ROC AUC:  0.58\n",
            "Log loss:  1.48\n",
            "G-mean:  0.6\n",
            "Optimal threshold:  0.05\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Boosted Tree \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.98      0.71      0.82       262\n",
            "    Counterfeit product       0.16      0.79      0.27        19\n",
            "\n",
            "               accuracy                           0.72       281\n",
            "              macro avg       0.57      0.75      0.55       281\n",
            "           weighted avg       0.92      0.72      0.79       281\n",
            "\n",
            "ROC AUC:  0.8\n",
            "Log loss:  0.44\n",
            "G-mean:  0.75\n",
            "Optimal threshold:  0.4\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Random Forest \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.97      0.85      0.91       262\n",
            "    Counterfeit product       0.25      0.68      0.36        19\n",
            "\n",
            "               accuracy                           0.84       281\n",
            "              macro avg       0.61      0.77      0.63       281\n",
            "           weighted avg       0.92      0.84      0.87       281\n",
            "\n",
            "ROC AUC:  0.85\n",
            "Log loss:  0.19\n",
            "G-mean:  0.76\n",
            "Optimal threshold:  0.09\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " SVM \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.99      0.64      0.77       262\n",
            "    Counterfeit product       0.15      0.89      0.26        19\n",
            "\n",
            "               accuracy                           0.65       281\n",
            "              macro avg       0.57      0.77      0.52       281\n",
            "           weighted avg       0.93      0.65      0.74       281\n",
            "\n",
            "ROC AUC:  0.82\n",
            "Log loss:  0.21\n",
            "G-mean:  0.76\n",
            "Optimal threshold:  0.04\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Build Naive Bayes and a sequential model with sentence embedding (300 dimensions) (10 pts.)\n",
        "# 3. Assess model performance, pick one metric to compare model performance and explain your metric choice. (10 pts.)\n",
        "# Youden's J statistic\n",
        "# Listing the models that will be built.\n",
        "# names = [\"Naive Bayes\", \"Logistic Regression\", \"Decision Tree\", \"Boosted Tree\", \"Random Forest\", \"SVM\"]\n",
        "\n",
        "# Define the corresponding list of classifiers, setting parameters where needed\n",
        "# classifiers = [MultinomialNB(),\n",
        "               # LogisticRegression(),\n",
        "               # DecisionTreeClassifier(max_depth = 5),\n",
        "               # AdaBoostClassifier(), \n",
        "               # RandomForestClassifier(max_depth = 5, n_estimators = 10),\n",
        "               # SVC(probability = True), \n",
        "               # ]\n",
        "\n",
        "# Define a dictionary to store the optimal thresholds for each model\n",
        "# thresholds = {}\n",
        "\n",
        "# Fit each classifier to the training set, make predictions on the test set,\n",
        "# evaluate performance, and find the optimal threshold for each model\n",
        "# for name, clf in zip(names, classifiers):\n",
        "    # clf_pipe = Pipeline([\n",
        "        # ('tfidf', TfidfVectorizer(max_df = 0.9, max_features = 5000,\n",
        "                                  # min_df = 0.1,\n",
        "                                  # use_idf = True, tokenizer = tokenize_and_stem, ngram_range = (1, 3))), \n",
        "        # (name, clf)\n",
        "    # ])\n",
        "  \n",
        "    # clf_pipe.fit(X_train_o, y_train_o)\n",
        "\n",
        "    # pred_prob = clf_pipe.predict_proba(X_test_o)[:, 1]\n",
        "    # fpr, tpr, thresholds_ = roc_curve(y_test_o, pred_prob)\n",
        "\n",
        "    # Compute the Youden's J statistic for each threshold\n",
        "    # J = tpr - fpr\n",
        "    # optimal_idx = np.argmax(J)\n",
        "    # optimal_threshold = thresholds_[optimal_idx]\n",
        "\n",
        "    # Store the optimal threshold in the dictionary\n",
        "    # thresholds[name] = optimal_threshold\n",
        "\n",
        "    # Make predictions using the optimal threshold\n",
        "    # pred = (pred_prob >= optimal_threshold).astype(int)\n",
        "\n",
        "    # roc_auc = roc_auc_score(y_test_o, pred_prob)\n",
        "    # log_loss_val = log_loss(y_test_o, pred_prob)\n",
        "\n",
        "    # target_names = ['Not counterfeit product', 'Counterfeit product']\n",
        "\n",
        "    # print('\\n\\n', name, '\\n\\n')\n",
        "    # print(classification_report(y_test_o, pred, target_names = target_names))\n",
        "    # print('ROC AUC: ', round(roc_auc, 2))\n",
        "    # print('Log loss: ', round(log_loss_val, 2))\n",
        "    # print('Optimal threshold: ', round(optimal_threshold, 2))\n",
        "    # print('\\n\\n')"
      ],
      "metadata": {
        "id": "PTM1ZZW_nphI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Builsequential model with sentence embedding (300 dimensions).\n",
        "# Pre-processing reviews for modeling.\n",
        "vocab_size = 5000\n",
        "embedding_dim = 300\n",
        "max_length = 500\n",
        "trunc_type ='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(X_train_o)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(X_train_o)\n",
        "testing_sequences = tokenizer.texts_to_sequences(X_test_o)\n",
        "\n",
        "# Padding\n",
        "padded = pad_sequences(sequences, maxlen = max_length, truncating = trunc_type) \n",
        "testing_padded = pad_sequences(testing_sequences, maxlen = max_length)  "
      ],
      "metadata": {
        "id": "geIH2PjvzHuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a 2-layer (100, 100) fully-connected neural network model using review length 500 and 300-dimension.\n",
        "# Using activation ='sigmoid', loss ='binary_crossentropy'\n",
        "model_500_300_o = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation ='relu'),\n",
        "    tf.keras.layers.Dense(100, activation ='relu'),\n",
        "    tf.keras.layers.Dense(1, activation ='sigmoid')\n",
        "])\n",
        "model_500_300_o.compile(loss ='binary_crossentropy', optimizer ='adam', metrics = [tf.keras.metrics.AUC(name = 'roc_auc')])\n",
        "model_500_300_o.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIG5DkI__UV3",
        "outputId": "725d4c5e-9e59-4cc2-f6b1-b62121c8a56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 300)          1500000   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 150000)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               15000100  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,510,301\n",
            "Trainable params: 16,510,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model.\n",
        "num_epochs = 100\n",
        "history = model_500_300_o.fit(padded, y_train_o, epochs = num_epochs, validation_data = (testing_padded, y_test_o))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBu7AuJNzHzj",
        "outputId": "00872ea4-0d9e-42a9-97d9-939258c08174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 4s 157ms/step - loss: 0.2847 - roc_auc: 0.5533 - val_loss: 0.2475 - val_roc_auc: 0.8712\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 0.1853 - roc_auc: 0.7075 - val_loss: 0.2147 - val_roc_auc: 0.9024\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 3s 166ms/step - loss: 0.1267 - roc_auc: 0.8737 - val_loss: 0.1305 - val_roc_auc: 0.9471\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 3s 150ms/step - loss: 0.0440 - roc_auc: 0.9838 - val_loss: 0.0938 - val_roc_auc: 0.9633\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 2s 139ms/step - loss: 0.0191 - roc_auc: 0.9786 - val_loss: 0.0838 - val_roc_auc: 0.9744\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 0.0109 - roc_auc: 0.9992 - val_loss: 0.0979 - val_roc_auc: 0.9600\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 3s 162ms/step - loss: 0.0063 - roc_auc: 1.0000 - val_loss: 0.1050 - val_roc_auc: 0.9632\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 0.0032 - roc_auc: 1.0000 - val_loss: 0.1039 - val_roc_auc: 0.9634\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 0.0017 - roc_auc: 1.0000 - val_loss: 0.1014 - val_roc_auc: 0.9632\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 7.1920e-04 - roc_auc: 1.0000 - val_loss: 0.1356 - val_roc_auc: 0.9417\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 6.0566e-04 - roc_auc: 1.0000 - val_loss: 0.1432 - val_roc_auc: 0.9165\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 3s 167ms/step - loss: 4.3074e-04 - roc_auc: 1.0000 - val_loss: 0.1199 - val_roc_auc: 0.9652\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 3s 141ms/step - loss: 2.6432e-04 - roc_auc: 1.0000 - val_loss: 0.1423 - val_roc_auc: 0.9166\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 3s 152ms/step - loss: 1.9758e-04 - roc_auc: 1.0000 - val_loss: 0.1510 - val_roc_auc: 0.9168\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 1.7025e-04 - roc_auc: 1.0000 - val_loss: 0.1538 - val_roc_auc: 0.9167\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 3s 170ms/step - loss: 1.7081e-04 - roc_auc: 1.0000 - val_loss: 0.1480 - val_roc_auc: 0.9167\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 3s 142ms/step - loss: 1.2500e-04 - roc_auc: 1.0000 - val_loss: 0.1517 - val_roc_auc: 0.9168\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 3s 153ms/step - loss: 1.1133e-04 - roc_auc: 1.0000 - val_loss: 0.1594 - val_roc_auc: 0.9169\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 1.0185e-04 - roc_auc: 1.0000 - val_loss: 0.1554 - val_roc_auc: 0.9169\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 3s 154ms/step - loss: 8.6683e-05 - roc_auc: 1.0000 - val_loss: 0.1610 - val_roc_auc: 0.8911\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 3s 153ms/step - loss: 7.7735e-05 - roc_auc: 1.0000 - val_loss: 0.1617 - val_roc_auc: 0.8911\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 3s 147ms/step - loss: 7.0396e-05 - roc_auc: 1.0000 - val_loss: 0.1650 - val_roc_auc: 0.8915\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 6.4121e-05 - roc_auc: 1.0000 - val_loss: 0.1652 - val_roc_auc: 0.8915\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 5.8256e-05 - roc_auc: 1.0000 - val_loss: 0.1683 - val_roc_auc: 0.8915\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 3s 169ms/step - loss: 5.3809e-05 - roc_auc: 1.0000 - val_loss: 0.1698 - val_roc_auc: 0.8915\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 5.0029e-05 - roc_auc: 1.0000 - val_loss: 0.1740 - val_roc_auc: 0.8914\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 4.5897e-05 - roc_auc: 1.0000 - val_loss: 0.1725 - val_roc_auc: 0.8915\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 3s 141ms/step - loss: 4.3136e-05 - roc_auc: 1.0000 - val_loss: 0.1724 - val_roc_auc: 0.8915\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 3.9328e-05 - roc_auc: 1.0000 - val_loss: 0.1749 - val_roc_auc: 0.8914\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 3s 142ms/step - loss: 3.6841e-05 - roc_auc: 1.0000 - val_loss: 0.1770 - val_roc_auc: 0.8915\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 3s 140ms/step - loss: 3.4712e-05 - roc_auc: 1.0000 - val_loss: 0.1768 - val_roc_auc: 0.8915\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 3s 147ms/step - loss: 3.2480e-05 - roc_auc: 1.0000 - val_loss: 0.1795 - val_roc_auc: 0.8919\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 3s 150ms/step - loss: 3.0491e-05 - roc_auc: 1.0000 - val_loss: 0.1794 - val_roc_auc: 0.8919\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 3s 168ms/step - loss: 2.8876e-05 - roc_auc: 1.0000 - val_loss: 0.1801 - val_roc_auc: 0.8919\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 3s 143ms/step - loss: 2.6948e-05 - roc_auc: 1.0000 - val_loss: 0.1815 - val_roc_auc: 0.8919\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 3s 154ms/step - loss: 2.5609e-05 - roc_auc: 1.0000 - val_loss: 0.1855 - val_roc_auc: 0.8921\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 2.4151e-05 - roc_auc: 1.0000 - val_loss: 0.1849 - val_roc_auc: 0.8921\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 3s 164ms/step - loss: 2.2880e-05 - roc_auc: 1.0000 - val_loss: 0.1854 - val_roc_auc: 0.8921\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 3s 145ms/step - loss: 2.1823e-05 - roc_auc: 1.0000 - val_loss: 0.1853 - val_roc_auc: 0.8921\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 2.0657e-05 - roc_auc: 1.0000 - val_loss: 0.1871 - val_roc_auc: 0.8922\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 3s 141ms/step - loss: 1.9716e-05 - roc_auc: 1.0000 - val_loss: 0.1868 - val_roc_auc: 0.8922\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 3s 151ms/step - loss: 1.8872e-05 - roc_auc: 1.0000 - val_loss: 0.1900 - val_roc_auc: 0.8923\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 3s 150ms/step - loss: 1.7907e-05 - roc_auc: 1.0000 - val_loss: 0.1888 - val_roc_auc: 0.8923\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 1.7056e-05 - roc_auc: 1.0000 - val_loss: 0.1897 - val_roc_auc: 0.8923\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 3s 140ms/step - loss: 1.6394e-05 - roc_auc: 1.0000 - val_loss: 0.1897 - val_roc_auc: 0.8923\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 1.5632e-05 - roc_auc: 1.0000 - val_loss: 0.1912 - val_roc_auc: 0.8923\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 3s 167ms/step - loss: 1.5083e-05 - roc_auc: 1.0000 - val_loss: 0.1942 - val_roc_auc: 0.8927\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 3s 150ms/step - loss: 1.4323e-05 - roc_auc: 1.0000 - val_loss: 0.1922 - val_roc_auc: 0.8923\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 1.3750e-05 - roc_auc: 1.0000 - val_loss: 0.1930 - val_roc_auc: 0.8923\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 3s 140ms/step - loss: 1.3217e-05 - roc_auc: 1.0000 - val_loss: 0.1936 - val_roc_auc: 0.8927\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 1.2691e-05 - roc_auc: 1.0000 - val_loss: 0.1949 - val_roc_auc: 0.8927\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 1.2249e-05 - roc_auc: 1.0000 - val_loss: 0.1965 - val_roc_auc: 0.8927\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 1.1724e-05 - roc_auc: 1.0000 - val_loss: 0.1967 - val_roc_auc: 0.8927\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 3s 141ms/step - loss: 1.1460e-05 - roc_auc: 1.0000 - val_loss: 0.1960 - val_roc_auc: 0.8927\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 3s 139ms/step - loss: 1.0911e-05 - roc_auc: 1.0000 - val_loss: 0.1976 - val_roc_auc: 0.8927\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 3s 170ms/step - loss: 1.0534e-05 - roc_auc: 1.0000 - val_loss: 0.1979 - val_roc_auc: 0.8925\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 3s 157ms/step - loss: 1.0177e-05 - roc_auc: 1.0000 - val_loss: 0.1983 - val_roc_auc: 0.8925\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 3s 186ms/step - loss: 9.8207e-06 - roc_auc: 1.0000 - val_loss: 0.1991 - val_roc_auc: 0.8925\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 3s 164ms/step - loss: 9.5307e-06 - roc_auc: 1.0000 - val_loss: 0.2016 - val_roc_auc: 0.8921\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 9.1498e-06 - roc_auc: 1.0000 - val_loss: 0.2022 - val_roc_auc: 0.8921\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 3s 145ms/step - loss: 8.8469e-06 - roc_auc: 1.0000 - val_loss: 0.2023 - val_roc_auc: 0.8921\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 8.5771e-06 - roc_auc: 1.0000 - val_loss: 0.2019 - val_roc_auc: 0.8921\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 8.2940e-06 - roc_auc: 1.0000 - val_loss: 0.2029 - val_roc_auc: 0.8924\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 8.1459e-06 - roc_auc: 1.0000 - val_loss: 0.2020 - val_roc_auc: 0.8921\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 7.7789e-06 - roc_auc: 1.0000 - val_loss: 0.2032 - val_roc_auc: 0.8924\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 3s 147ms/step - loss: 7.5720e-06 - roc_auc: 1.0000 - val_loss: 0.2035 - val_roc_auc: 0.8924\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 2s 139ms/step - loss: 7.3426e-06 - roc_auc: 1.0000 - val_loss: 0.2055 - val_roc_auc: 0.8924\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 7.1184e-06 - roc_auc: 1.0000 - val_loss: 0.2055 - val_roc_auc: 0.8924\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 3s 164ms/step - loss: 6.9048e-06 - roc_auc: 1.0000 - val_loss: 0.2073 - val_roc_auc: 0.8924\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 6.6724e-06 - roc_auc: 1.0000 - val_loss: 0.2063 - val_roc_auc: 0.8924\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 6.4803e-06 - roc_auc: 1.0000 - val_loss: 0.2068 - val_roc_auc: 0.8924\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 3s 143ms/step - loss: 6.3095e-06 - roc_auc: 1.0000 - val_loss: 0.2081 - val_roc_auc: 0.8924\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 6.1033e-06 - roc_auc: 1.0000 - val_loss: 0.2079 - val_roc_auc: 0.8924\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 5.9719e-06 - roc_auc: 1.0000 - val_loss: 0.2072 - val_roc_auc: 0.8924\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 5.7898e-06 - roc_auc: 1.0000 - val_loss: 0.2088 - val_roc_auc: 0.8927\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 2s 140ms/step - loss: 5.6281e-06 - roc_auc: 1.0000 - val_loss: 0.2093 - val_roc_auc: 0.8927\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 3s 147ms/step - loss: 5.4672e-06 - roc_auc: 1.0000 - val_loss: 0.2097 - val_roc_auc: 0.8927\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 3s 192ms/step - loss: 5.3453e-06 - roc_auc: 1.0000 - val_loss: 0.2096 - val_roc_auc: 0.8927\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 3s 147ms/step - loss: 5.1910e-06 - roc_auc: 1.0000 - val_loss: 0.2106 - val_roc_auc: 0.8927\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 5.0634e-06 - roc_auc: 1.0000 - val_loss: 0.2121 - val_roc_auc: 0.8927\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 3s 140ms/step - loss: 4.9318e-06 - roc_auc: 1.0000 - val_loss: 0.2110 - val_roc_auc: 0.8927\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 3s 154ms/step - loss: 4.7949e-06 - roc_auc: 1.0000 - val_loss: 0.2113 - val_roc_auc: 0.8927\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 4.6672e-06 - roc_auc: 1.0000 - val_loss: 0.2117 - val_roc_auc: 0.8927\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 3s 146ms/step - loss: 4.5713e-06 - roc_auc: 1.0000 - val_loss: 0.2121 - val_roc_auc: 0.8927\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 2s 139ms/step - loss: 4.4654e-06 - roc_auc: 1.0000 - val_loss: 0.2143 - val_roc_auc: 0.8927\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 3s 145ms/step - loss: 4.3467e-06 - roc_auc: 1.0000 - val_loss: 0.2137 - val_roc_auc: 0.8927\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 3s 165ms/step - loss: 4.2301e-06 - roc_auc: 1.0000 - val_loss: 0.2146 - val_roc_auc: 0.8927\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 3s 141ms/step - loss: 4.1304e-06 - roc_auc: 1.0000 - val_loss: 0.2150 - val_roc_auc: 0.8927\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 3s 145ms/step - loss: 4.0315e-06 - roc_auc: 1.0000 - val_loss: 0.2159 - val_roc_auc: 0.8927\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 3.9297e-06 - roc_auc: 1.0000 - val_loss: 0.2160 - val_roc_auc: 0.8927\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 3s 153ms/step - loss: 3.8409e-06 - roc_auc: 1.0000 - val_loss: 0.2165 - val_roc_auc: 0.8927\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 3s 148ms/step - loss: 3.7750e-06 - roc_auc: 1.0000 - val_loss: 0.2158 - val_roc_auc: 0.8927\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 3.6700e-06 - roc_auc: 1.0000 - val_loss: 0.2165 - val_roc_auc: 0.8927\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 3s 145ms/step - loss: 3.5949e-06 - roc_auc: 1.0000 - val_loss: 0.2180 - val_roc_auc: 0.8923\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 3.4943e-06 - roc_auc: 1.0000 - val_loss: 0.2171 - val_roc_auc: 0.8925\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 3s 169ms/step - loss: 3.4221e-06 - roc_auc: 1.0000 - val_loss: 0.2173 - val_roc_auc: 0.8925\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 3s 144ms/step - loss: 3.3545e-06 - roc_auc: 1.0000 - val_loss: 0.2188 - val_roc_auc: 0.8923\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 2s 138ms/step - loss: 3.3102e-06 - roc_auc: 1.0000 - val_loss: 0.2175 - val_roc_auc: 0.8923\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 2s 138ms/step - loss: 3.1991e-06 - roc_auc: 1.0000 - val_loss: 0.2180 - val_roc_auc: 0.8923\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 3.1320e-06 - roc_auc: 1.0000 - val_loss: 0.2190 - val_roc_auc: 0.8923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding optimal threshold and evaluating the model.\n",
        "y_pred_proba_o = model_500_300_o.predict(testing_padded)\n",
        "y_pred_proba_o = y_pred_proba_o[:, 0]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test_o, y_pred_proba_o)\n",
        "sort_idx = np.argsort(thresholds)\n",
        "fpr = fpr[sort_idx]\n",
        "tpr = tpr[sort_idx]\n",
        "thresholds = thresholds[sort_idx]\n",
        "\n",
        "gmeans_ker = np.sqrt(tpr * (1-fpr))\n",
        "gmeans_ker[np.isnan(gmeans_ker)] = 0\n",
        "\n",
        "optimal_idx = np.argmax(gmeans_ker)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "y_pred = (y_pred_proba_o >= optimal_threshold).astype(int)\n",
        "\n",
        "log_loss_val = log_loss(y_test_o, y_pred_proba_o)\n",
        "\n",
        "print(classification_report(y_test_o, y_pred, target_names = target_names))\n",
        "print('ROC AUC: ', round(auc(fpr, tpr), 2))\n",
        "print(\"Optimal Threshold:\", round(optimal_threshold, 20))\n",
        "print('Log loss: ', round(log_loss_val, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "279R6eVT2Vhn",
        "outputId": "75419b11-0c32-42d9-cea6-296dddc4d5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 20ms/step\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       1.00      0.92      0.95       262\n",
            "    Counterfeit product       0.45      0.95      0.61        19\n",
            "\n",
            "               accuracy                           0.92       281\n",
            "              macro avg       0.72      0.93      0.78       281\n",
            "           weighted avg       0.96      0.92      0.93       281\n",
            "\n",
            "ROC AUC:  0.97\n",
            "Optimal Threshold: 0.00010273724\n",
            "Log loss:  0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the Neural Network model performance.\n",
        "# y_pred_o = model_500_300_o.predict(testing_padded)\n",
        "# y_pred_o = (y_pred_o >= 0.5)\n",
        "\n",
        "# fpr, tpr, thresholds = roc_curve(y_test_o, y_pred_o)\n",
        "# log_loss_val = log_loss(y_test_o, y_pred_o)\n",
        "\n",
        "# print(classification_report(y_test_o, y_pred_o, target_names = target_names))\n",
        "# print('ROC AUC: ', round(auc(fpr, tpr), 2))\n",
        "# print('Log loss: ', round(log_loss_val, 2))"
      ],
      "metadata": {
        "id": "9ANL1CkR1bzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy, Precision, Recall, and F-measure are threshold-dependent metrics. ROC curve and AUC are threshold-independent. Youden's J statistic and G-means were used to find an optimal threshold. \n",
        "- ROC AUC:\n",
        "     - Naive Bayes: 0.88\n",
        "     - Logistic Regression: 0.89\n",
        "     - Decision Tree: 0.58\n",
        "     - Boosted Tree: 0.80\n",
        "     - Random Forest: 0.83\n",
        "     - SVM: 0.82\n",
        "     - Keras: 0.97\n",
        "\n",
        "Keras model has the best performance based on ROC AUC metric of 0.97 and optimal threshold of 0.00010273724.\n",
        "\n",
        "Logistic Regression has the second best performance based on ROC AUC metric of 0.89 and optimal threshold of 0.08.\n",
        "\n",
        "Becase the Keras optimal threshold is very small (almost equal to zero), the feaure importance for the non-counterfeit (0) product and counterfeit product (1) are the same.\n",
        "\n",
        "We will use Naive Bayes model with ROC AUC of 0.88, optimal threshold of 0.06 for feature extraction. \n"
      ],
      "metadata": {
        "id": "HMtKNnMCPmmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes feature importance.**"
      ],
      "metadata": {
        "id": "ST_LLA1CubsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 1. No optimal threshold.\n",
        "# Rebuilding the Naive Bayes model.\n",
        "vectorizer = TfidfVectorizer(ngram_range = (2, 3))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_o)\n",
        "\n",
        "selector = SelectKBest(chi2, k = 'all')\n",
        "selector.fit(X_train_tfidf, y_train_o)\n",
        "\n",
        "X_train_selected = selector.transform(X_train_tfidf)\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_selected, y_train_o)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "selected_mask = selector.get_support()\n",
        "selected_features = [feature_names[i] for i in range(len(feature_names)) if selected_mask[i]]\n",
        "\n",
        "top_negative = np.argsort(nb.feature_log_prob_[1])[::-1][:10]\n",
        "top_positive = np.argsort(nb.feature_log_prob_[0])[::-1][:10]\n",
        "\n",
        "print(\"Top non-counterfeit features:\", [selected_features[i] for i in top_positive])\n",
        "print(\"Top counterfeit features:\", [selected_features[i] for i in top_negative])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34Q9tOQVbtyZ",
        "outputId": "73ade905-75bc-4eac-9a46-3f3598628212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top non-counterfeit features: ['works great', 'great product', 'ove glove', 'ove gloves', 'oven mitt', 'works well', 'good product', 'hot items', 'love ove', 'great price']\n",
            "Top counterfeit features: ['real ove', 'ove glove', 'real ove glove', 'loop hang', 'ove gloves', 'real ove gloves', 'missing loop', 'missing loop hang', 'real deal', 'came china']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top counterfeit features:\n",
        "- 'ove glove', 'real ove glove', 'real ove': \n",
        "\n",
        "These features apperar in 26 reviws.\n",
        "\n",
        "     - We own other ove gloves and the one we received is definitely a fake.  The box is full of spelling errors that tipped me off that this wasn't the real deal..  The glove doesn't have the same shape/elasticity as the real one we have.  I should have read the reviews but was misled since it said Amazon's Choice on the listing.  Real ove gloves are fantastic, wasn't going to take chances with this fake one.\n",
        "     - Fake product.  They're too small and they don't have the hanging loops.  Real Ove Gloves are great--  this is nothing.  Avoid.\n",
        "\n",
        "- 'loop hang', 'missing loop', 'missing loop hang'\n",
        "\n",
        "These features apperar in 5 reviws.\n",
        "\n",
        "     - missing loop to hang it up.\n",
        "     - I love the real Ove Glove. What I received, however, was different from the one I had purchased several years ago. I believe it could have been counterfeit. Either that, or they have changed how they make them. There was no sewn in loop for hanging the glove up. Instead of a cloth tag with all of the info, there was only a small plastic (thermal BPA paper) tag. The amount of Kevalar to the other material changed. And it had an extremely strong chemical odor. Additionally, the silicone grip lines and letters were brighter and larger. I've returned it and now am hesitant of where I will order a replacement from. The first Ove Glove we had worked well for years until my husband washed and dried it. They can be machine washed, but they cannot do in a clothes dryer. Heat now goes through it much more quickly.\n",
        "\n",
        "- 'real deal':\n",
        "\n",
        "This feature apperars in 6 reviws.\n",
        "\n",
        "      - We own other ove gloves and the one we received is definitely a fake.  The box is full of spelling errors that tipped me off that this wasn't the real deal..  The glove doesn't have the same shape/elasticity as the real one we have.  I should have read the reviews but was misled since it said Amazon's Choice on the listing.  Real ove gloves are fantastic, wasn't going to take chances with this fake one.\n",
        "      - This was another fake as many others have posted.  Packaging looks great until you get inside and see the tell tale black seam on cuff, slightly different blue color and lack of tags.  It works OK as general potholder but I wouldn't test it to the limits listed on the packaging as I have no idea what it is really made of.  Price is inexpensive so that should be your clue.  I am disappointed that Amazon continues to use vendors that send out fake merchandise without making that amply clear in their description.  I tried very hard to get the real thing by reading all the reviews and picking the company that I believed would be sending out the real deal.  However I found that it was not shipped by the company I'd ordered from.\n",
        "\n",
        "- 'came china':\n",
        "\n",
        "This feature apperars in 9 reviws.\n",
        "\n",
        "     - came from china in clearly after market packaging. It smells of chemicals.  I ordered two gloves and it came stuffed in a one glove box.  The \"Ove Glove\" tag is not sewn into the glove like the others I own.  It is clearly a knock off!  Buyer beware of where you are buying from!\n",
        "     - I ordered two of these.  They came from China in plastic bags, not boxes as pictured.  I have small hands and they barely fit me.  And I can feel the heat right through them.  These gloves are no better than my old worn-out original Ove Gloves.  I am returning them.\n",
        "     - Do not order from Happyshopping2013.  It is a counterfeit item.  It came from China, without the original packaging and has no tag with the manufacturing and care instructions on the inside.  I have a real \"Ove\" glove and this is not it!\n",
        "\n",
        "- 'fake one':\n",
        "\n",
        "This feature apperars in 2 reviws.\n",
        "\n",
        "     - We own other ove gloves and the one we received is definitely a fake.  The box is full of spelling errors that tipped me off that this wasn't the real deal..  The glove doesn't have the same shape/elasticity as the real one we have.  I should have read the reviews but was misled since it said Amazon's Choice on the listing.  Real ove gloves are fantastic, wasn't going to take chances with this fake one.\n",
        "     - Yes, you get two FAKE Ove Gloves sent to me by GF Sports. They are not as pictured but are the fake ones with the black stitching at the cuffs, no label, and no registration card. I thought Amazon had taken care of this but it looks like they have not done so.\n",
        "\n",
        "- 'glove like':\n",
        "\n",
        "This feature apperars in 3 reviws.\n",
        "\n",
        "     - came from china in clearly after market packaging. It smells of chemicals.  I ordered two gloves and it came stuffed in a one glove box.  The \"Ove Glove\" tag is not sewn into the glove like the others I own.  It is clearly a knock off!  Buyer beware of where you are buying from!\n",
        "     - I read the other reviews and it was confusing but THIS IS NOT THE OFFICIAL OVE GLOVE! I bought my first Ove Glove at Walgreen's and loved it so much I needed another. I went the cheap route and bought this one from JOSEPH ENTERPRISES. It has the the Ove Glove box but that's where the similarities end. The glove is tighter, a different blue, and it comes with a black band around the wrist (not pictured in their misleading add). It also has no tag inside the glove like the original one. Most importantly of all: It doesn't protect from heat like the original Ove Glove. Please heed my warning: DO NOT BUY THIS PRODUCT FROM THIS SELLER!\n"
      ],
      "metadata": {
        "id": "OAT_h89SDNGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 2. With optimal treshold.\n",
        "thresholds = {}\n",
        "\n",
        "# Rebuilding Naive Bayes model.\n",
        "names = 'Naive Bayes'\n",
        "nb = MultinomialNB()\n",
        "\n",
        "nb_pipe = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_df = 0.9, max_features = 5000,\n",
        "                              min_df = 0.1,\n",
        "                              use_idf = True, tokenizer = tokenize_and_stem, ngram_range = (1, 3))), \n",
        "    ('nb', nb)\n",
        "])\n",
        "\n",
        "nb_pipe.fit(X_train_o, y_train_o)\n",
        "\n",
        "pred_prob = nb_pipe.predict_proba(X_test_o)[:, 1]\n",
        "\n",
        "# Computing the G-mean for each threshold.\n",
        "g_mean = []\n",
        "for thresh in thresholds_:\n",
        "    pred = (pred_prob >= thresh).astype(int)\n",
        "    g_mean.append(geometric_mean_score(y_test_o, pred))\n",
        "\n",
        "# Choosing the threshold that maximizes the G-mean.\n",
        "optimal_idx = np.argmax(g_mean)\n",
        "optimal_threshold = thresholds_[optimal_idx]\n",
        "\n",
        "# Storing the optimal threshold in the dictionary.\n",
        "thresholds[name] = optimal_threshold\n",
        "\n",
        "# Making predictions using the optimal threshold.\n",
        "pred = (pred_prob >= optimal_threshold).astype(int)\n",
        "\n",
        "# Get the feature probabilities from the classifier\n",
        "feature_probs = nb.feature_log_prob_\n",
        "\n",
        "# Get the feature names from the TfidfVectorizer\n",
        "feature_names = nb_pipe.named_steps['tfidf'].get_feature_names_out()\n",
        "\n",
        "# Sort the feature probabilities for class 0 (non-counterfeit)\n",
        "sorted_probs_0 = np.argsort(feature_probs[0])[::-1]\n",
        "top_features_0 = [feature_names[i] for i in sorted_probs_0[:10]]\n",
        "\n",
        "# Sort the feature probabilities for class 1 (counterfeit)\n",
        "sorted_probs_1 = np.argsort(feature_probs[1])[::-1]\n",
        "top_features_1 = [feature_names[i] for i in sorted_probs_1[:10]]\n",
        "\n",
        "print('Top features for non-counterfeit (class 0):', top_features_0)\n",
        "print('Top features for counterfeit (class 1):', top_features_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66rWyHFNf0_M",
        "outputId": "5f7d2f6c-af22-4170-f259-ed884e8e598f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top features for non-counterfeit (class 0): ['great', 'glove', 'use', 'work', 'one', 'oven', 'love', 'hot', 'product', 'hand']\n",
            "Top features for counterfeit (class 1): ['glove', 'ove glove', 'ove', 'one', 'get', 'use', 'heat', 'like', 'hand', 'product']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features for counterfeit and non-counterfeit products are almost identical, which does not make any sence."
      ],
      "metadata": {
        "id": "CFVmS4EKEXLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the Naive Bayes model and TfidfVectorizer from the pipeline.\n",
        "nb_model = nb_pipe.named_steps['nb']\n",
        "tfidf_vectorizer = nb_pipe.named_steps['tfidf']\n",
        "\n",
        "# Accessing the feature log probabilities from the Naive Bayes model.\n",
        "feature_log_prob = nb_model.feature_log_prob_\n",
        "\n",
        "# Getting the feature names from the TfidfVectorizer.\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Creating a DataFrame to store the feature names and their associated log probabilities for each class.\n",
        "df = pd.DataFrame({'feature_names': feature_names,\n",
        "                   'non_counterfeit_log_prob': feature_log_prob[0],\n",
        "                   'counterfeit_log_prob': feature_log_prob[1]})\n",
        "\n",
        "# Sorting the DataFrame by the log probabilities for the counterfeit class.\n",
        "df = df.sort_values('counterfeit_log_prob', ascending = False)\n",
        "\n",
        "# Getting the top 10 most informative features associated with counterfeit products (class 1).\n",
        "top_10_counterfeit = df.head(10)\n",
        "\n",
        "# Getting the top 10 most informative features associated with non-counterfeit products (class 0).\n",
        "top_10_non_counterfeit = df.tail(10)"
      ],
      "metadata": {
        "id": "yrB0Uk9ujEc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_counterfeit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lLvNbdMgn3il",
        "outputId": "1b06a376-17c0-433d-fb29-4f87d23438ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_names  non_counterfeit_log_prob  counterfeit_log_prob\n",
              "4          glove                 -2.450333             -1.843055\n",
              "13     ove glove                 -3.286165             -2.159462\n",
              "12           ove                 -3.280057             -2.162770\n",
              "11           one                 -2.658475             -2.664495\n",
              "2            get                 -3.353822             -2.875218\n",
              "16           use                 -2.587296             -2.895698\n",
              "7           heat                 -3.376047             -2.938541\n",
              "9           like                 -3.357387             -3.020224\n",
              "6           hand                 -2.995086             -3.023802\n",
              "15       product                 -2.963883             -3.032287"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52f7674e-1d57-412b-b654-75b9affb327b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_names</th>\n",
              "      <th>non_counterfeit_log_prob</th>\n",
              "      <th>counterfeit_log_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>glove</td>\n",
              "      <td>-2.450333</td>\n",
              "      <td>-1.843055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ove glove</td>\n",
              "      <td>-3.286165</td>\n",
              "      <td>-2.159462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ove</td>\n",
              "      <td>-3.280057</td>\n",
              "      <td>-2.162770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>one</td>\n",
              "      <td>-2.658475</td>\n",
              "      <td>-2.664495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>get</td>\n",
              "      <td>-3.353822</td>\n",
              "      <td>-2.875218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>use</td>\n",
              "      <td>-2.587296</td>\n",
              "      <td>-2.895698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>heat</td>\n",
              "      <td>-3.376047</td>\n",
              "      <td>-2.938541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>like</td>\n",
              "      <td>-3.357387</td>\n",
              "      <td>-3.020224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hand</td>\n",
              "      <td>-2.995086</td>\n",
              "      <td>-3.023802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>product</td>\n",
              "      <td>-2.963883</td>\n",
              "      <td>-3.032287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52f7674e-1d57-412b-b654-75b9affb327b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52f7674e-1d57-412b-b654-75b9affb327b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52f7674e-1d57-412b-b654-75b9affb327b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_non_counterfeit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vfBsiMtbjEh-",
        "outputId": "aa91d012-e2b8-4d27-b2ad-897d81331da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_names  non_counterfeit_log_prob  counterfeit_log_prob\n",
              "15       product                 -2.963883             -3.032287\n",
              "1           burn                 -3.432977             -3.317646\n",
              "17          work                 -2.633680             -3.464858\n",
              "18          year                 -3.349060             -3.490568\n",
              "0         bought                 -3.275060             -3.579105\n",
              "8            hot                 -2.898027             -3.636424\n",
              "3           gift                 -3.251307             -3.833951\n",
              "10          love                 -2.773553             -3.910132\n",
              "14          oven                 -2.697897             -3.954298\n",
              "5          great                 -2.440169             -3.998649"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c9e882d-c83a-4f4e-b8a7-1f01147e01bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_names</th>\n",
              "      <th>non_counterfeit_log_prob</th>\n",
              "      <th>counterfeit_log_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>product</td>\n",
              "      <td>-2.963883</td>\n",
              "      <td>-3.032287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>burn</td>\n",
              "      <td>-3.432977</td>\n",
              "      <td>-3.317646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>work</td>\n",
              "      <td>-2.633680</td>\n",
              "      <td>-3.464858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>year</td>\n",
              "      <td>-3.349060</td>\n",
              "      <td>-3.490568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought</td>\n",
              "      <td>-3.275060</td>\n",
              "      <td>-3.579105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hot</td>\n",
              "      <td>-2.898027</td>\n",
              "      <td>-3.636424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gift</td>\n",
              "      <td>-3.251307</td>\n",
              "      <td>-3.833951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>love</td>\n",
              "      <td>-2.773553</td>\n",
              "      <td>-3.910132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>oven</td>\n",
              "      <td>-2.697897</td>\n",
              "      <td>-3.954298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>great</td>\n",
              "      <td>-2.440169</td>\n",
              "      <td>-3.998649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c9e882d-c83a-4f4e-b8a7-1f01147e01bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c9e882d-c83a-4f4e-b8a7-1f01147e01bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c9e882d-c83a-4f4e-b8a7-1f01147e01bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "XIRYiArh6vtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8520d0-4fee-4032-b8f6-c0b37a91ab1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from shap) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from shap) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.9/dist-packages (from shap) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from shap) (1.5.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.9/dist-packages (from shap) (23.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->shap) (67.6.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->shap) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keras feature importance.**"
      ],
      "metadata": {
        "id": "kc8o0iVxZxmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# Creating an explainer object for the best model (Keras).\n",
        "explainer = shap.Explainer(model_500_300_o, testing_padded)\n",
        "\n",
        "# Generating SHAP values for the testing dataset.\n",
        "shap_values = explainer(testing_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1LmBBmome4Q",
        "outputId": "ef154ab6-0ed0-43eb-f5f6-5d9e154c6173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Permutation explainer: 282it [30:34,  6.57s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_values.abs.sum(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "7g_NQ7Xly-TK",
        "outputId": "afae4548-4b16-4ddb-ef98-b4f3f8e74fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x650 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the mean absolute SHAP values for each feature\n",
        "feature_importance = np.mean(np.abs(shap_values.values), axis=0)\n",
        "\n",
        "# Getting the names of the features (words)\n",
        "feature_names = [word for word, index in word_index.items() if index < vocab_size]\n",
        "\n",
        "feature_df = pd.DataFrame(list(zip(feature_names, feature_importance)), columns=['feature', 'importance'])\n",
        "feature_df = feature_df.sort_values('importance', ascending=False)\n",
        "print(feature_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGDnnkVUy-Yp",
        "outputId": "d684dcb1-de55-40f3-b5a4-62781596dd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      feature  importance\n",
            "499     stand    0.003956\n",
            "498   opinion    0.003471\n",
            "497      name    0.002708\n",
            "490     brand    0.002315\n",
            "488      save    0.002298\n",
            "482     bring    0.002277\n",
            "496   package    0.002261\n",
            "492      live    0.002247\n",
            "487  standard    0.002201\n",
            "494      kind    0.002097\n",
            "493     learn    0.001938\n",
            "491      i’ve    0.001908\n",
            "484     we’ve    0.001899\n",
            "485       add    0.001774\n",
            "495  compared    0.001745\n",
            "486       air    0.001642\n",
            "483  official    0.001487\n",
            "489   generic    0.001441\n",
            "481        nd    0.001329\n",
            "479   grabbed    0.001027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating features by class: 0 and 1.\n",
        "# Average the SHAP values for each feature over all the reviews in each class.\n",
        "shap_values_0 = shap_values[y_test_o.values == 0].mean(axis=0)\n",
        "shap_values_1 = shap_values[y_test_o.values == 1].mean(axis=0)"
      ],
      "metadata": {
        "id": "Pehp3Fhumnnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the feature names.\n",
        "feature_names = list(tokenizer.word_index.keys())"
      ],
      "metadata": {
        "id": "jg-iEfOTuRON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Explanation objects to numpy arrays\n",
        "shap_values_0_np = shap_values_0.values\n",
        "shap_values_1_np = shap_values_1.values\n",
        "\n",
        "# Sorting the features based on their average importance values.\n",
        "sorted_features_0 = [feature_names[i] for i in np.argsort(np.abs(shap_values_0_np))[::-1]]\n",
        "sorted_features_1 = [feature_names[i] for i in np.argsort(np.abs(shap_values_1_np))[::-1]]"
      ],
      "metadata": {
        "id": "wKogIN_-vQCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the top 20 features for each class.\n",
        "print(\"Top 20 features for non-counterfeit product (0):\")\n",
        "for feature in sorted_features_0[:20]:\n",
        "    print(feature)\n",
        "print()\n",
        "\n",
        "print(\"Top 20 features for counterfeit product (1):\")\n",
        "for feature in sorted_features_1[:20]:\n",
        "    print(feature)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SJagyAwnl9J",
        "outputId": "9a4882d8-40f8-4f77-b50c-8cfe2215163e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 features for non-counterfeit product (0):\n",
            "stand\n",
            "opinion\n",
            "bring\n",
            "brand\n",
            "standard\n",
            "i’ve\n",
            "add\n",
            "save\n",
            "we’ve\n",
            "package\n",
            "learn\n",
            "air\n",
            "live\n",
            "grabbed\n",
            "generic\n",
            "nd\n",
            "thicker\n",
            "straight\n",
            "cool\n",
            "messing\n",
            "\n",
            "Top 20 features for counterfeit product (1):\n",
            "opinion\n",
            "stand\n",
            "live\n",
            "name\n",
            "save\n",
            "package\n",
            "official\n",
            "kind\n",
            "brand\n",
            "bring\n",
            "compared\n",
            "we’ve\n",
            "standard\n",
            "air\n",
            "learn\n",
            "add\n",
            "i’ve\n",
            "generic\n",
            "nd\n",
            "grabbed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UGG Boots**"
      ],
      "metadata": {
        "id": "gPECU3B6dOid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset.\n",
        "ugg = pd.read_csv('UGG_label.csv')\n",
        "ugg.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "S3NG-OvTdaGi",
        "outputId": "21c908d0-0b25-4f33-900f-69dc0f8c908c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  review_date            handle  rating helpfulness_rating  Olga label  \\\n",
              "0    6-Mar-23    Bereniz Flores     5.0                NaN           0   \n",
              "1   23-Feb-23  JESSICA Zerlotta     5.0                  2           0   \n",
              "2    2-Mar-23          whiplash     5.0                One           0   \n",
              "3    2-Mar-23               Gia     5.0                NaN           0   \n",
              "4   27-Feb-23      Rollin Olson     5.0                NaN           0   \n",
              "\n",
              "   Amer label  Jason label  Justin label  Final label  \\\n",
              "0           0            0           NaN            0   \n",
              "1           0            0           NaN            0   \n",
              "2           0            0           NaN            0   \n",
              "3           0            0           NaN            0   \n",
              "4           0            0           NaN            0   \n",
              "\n",
              "                                              review  \n",
              "0  I love my boots especially since I was able to...  \n",
              "1  Southern California girl here…. I want to use ...  \n",
              "2  Wife is 5’7 and has a muscular calf and likes ...  \n",
              "3  These are good quality. The texture is really ...  \n",
              "4                          My wife is enjoying these  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcb42f36-61da-4eec-bf73-896bce1ddb92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_date</th>\n",
              "      <th>handle</th>\n",
              "      <th>rating</th>\n",
              "      <th>helpfulness_rating</th>\n",
              "      <th>Olga label</th>\n",
              "      <th>Amer label</th>\n",
              "      <th>Jason label</th>\n",
              "      <th>Justin label</th>\n",
              "      <th>Final label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6-Mar-23</td>\n",
              "      <td>Bereniz Flores</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>I love my boots especially since I was able to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23-Feb-23</td>\n",
              "      <td>JESSICA Zerlotta</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Southern California girl here…. I want to use ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2-Mar-23</td>\n",
              "      <td>whiplash</td>\n",
              "      <td>5.0</td>\n",
              "      <td>One</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Wife is 5’7 and has a muscular calf and likes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2-Mar-23</td>\n",
              "      <td>Gia</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>These are good quality. The texture is really ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27-Feb-23</td>\n",
              "      <td>Rollin Olson</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife is enjoying these</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcb42f36-61da-4eec-bf73-896bce1ddb92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcb42f36-61da-4eec-bf73-896bce1ddb92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcb42f36-61da-4eec-bf73-896bce1ddb92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ugg.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsl7kwBBeMOQ",
        "outputId": "a6ceccf4-3419-42d5-d8fb-e5c1d94bf067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1101 entries, 0 to 1100\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   review_date         1101 non-null   object \n",
            " 1   handle              1101 non-null   object \n",
            " 2   rating              1003 non-null   float64\n",
            " 3   helpfulness_rating  204 non-null    object \n",
            " 4   Olga label          1101 non-null   int64  \n",
            " 5   Amer label          1101 non-null   int64  \n",
            " 6   Jason label         1101 non-null   int64  \n",
            " 7   Justin label        0 non-null      float64\n",
            " 8   Final label         1101 non-null   int64  \n",
            " 9   review              1101 non-null   object \n",
            "dtypes: float64(2), int64(4), object(4)\n",
            "memory usage: 86.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ugg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4WiZ5IuePNN",
        "outputId": "3d4af5b6-a966-418a-85d7-d08b4fe3446b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1101, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has 1101 rows and 10 columns. Each row represents a review for a given product. "
      ],
      "metadata": {
        "id": "TQG8Thx6eWX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting all values in \"Final Label\" column.\n",
        "print(ugg['Final label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g0569_meTII",
        "outputId": "471dbcde-d6f1-46a1-8118-90ed574b42ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1038\n",
            "1      63\n",
            "Name: Final label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating persantage of values in the 'Final label' column.\n",
        "print(ugg['Final label'].value_counts(normalize=True).mul(100).round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4i3lCpVgR7d",
        "outputId": "8d2955dc-982c-4335-f92e-c2bec5fcd248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    94.28\n",
            "1     5.72\n",
            "Name: Final label, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Final label' column has values 0, 1. They represent:\n",
        "- Not counterfeit product as 0,\n",
        "- Counterfeit product as 1,\n",
        "\n",
        "The dataset has:\n",
        "- Not counterfeit product reviews: 1038 (94.28%)\n",
        "- Counterfeit product reviews: 63 (5.72%)\n",
        "\n"
      ],
      "metadata": {
        "id": "8kt0uYkoeeWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping columns that are not useful.\n",
        "ugg.drop(columns = ['review_date','handle','helpfulness_rating', 'Amer label', 'Olga label', 'Jason label', 'Justin label'], inplace = True)\n",
        "ugg.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mny79lLpjMkd",
        "outputId": "c11f5c30-4a46-43e1-88d7-da660d4e3673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  Final label                                             review\n",
              "0     5.0            0  I love my boots especially since I was able to...\n",
              "1     5.0            0  Southern California girl here…. I want to use ...\n",
              "2     5.0            0  Wife is 5’7 and has a muscular calf and likes ...\n",
              "3     5.0            0  These are good quality. The texture is really ...\n",
              "4     5.0            0                          My wife is enjoying these"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-563a03ff-b0f3-47f3-a45e-a5c50c5e9863\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>Final label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>I love my boots especially since I was able to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Southern California girl here…. I want to use ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Wife is 5’7 and has a muscular calf and likes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>These are good quality. The texture is really ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife is enjoying these</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-563a03ff-b0f3-47f3-a45e-a5c50c5e9863')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-563a03ff-b0f3-47f3-a45e-a5c50c5e9863 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-563a03ff-b0f3-47f3-a45e-a5c50c5e9863');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pre-process data as appropriate (10 pts.)\n",
        "# Applying the function to the column in DataFrame.\n",
        "ugg['review'] = ugg['review'].apply(review_preprocess)\n",
        "ugg.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eZ3rk7u3jh27",
        "outputId": "8234159f-c629-4a68-8503-4b099117246f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  Final label                                             review\n",
              "0     5.0            0  love boots especially since able affirm make p...\n",
              "1     5.0            0  southern california girl here… want use boots ...\n",
              "2     5.0            0  wife ’ muscular calf likes tight fit style wid...\n",
              "3     5.0            0                   good quality texture really soft\n",
              "4     5.0            0                                      wife enjoying"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e58f0b9-7069-45d4-bf2f-e8f5d748c303\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>Final label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>love boots especially since able affirm make p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>southern california girl here… want use boots ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>wife ’ muscular calf likes tight fit style wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>good quality texture really soft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>wife enjoying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e58f0b9-7069-45d4-bf2f-e8f5d748c303')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e58f0b9-7069-45d4-bf2f-e8f5d748c303 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e58f0b9-7069-45d4-bf2f-e8f5d748c303');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into training and testing.\n",
        "X_u = ugg['review']\n",
        "y_u = ugg['Final label']\n",
        "\n",
        "X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(X_u, y_u, test_size = 0.33, random_state = 101)"
      ],
      "metadata": {
        "id": "jCf-L7OVj65D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Build Naive Bayes and a sequential model with sentence embedding (300 dimensions) (10 pts.)\n",
        "# 3. Assess model performance, pick one metric to compare model performance and explain your metric choice. (10 pts.)\n",
        "# G-means.\n",
        "# Listing the models that will be built.\n",
        "names = [\"Naive Bayes\", \"Logistic Regression\", \"Decision Tree\", \"Boosted Tree\", \"Random Forest\", \"SVM\"]\n",
        "\n",
        "# Defining the corresponding list of classifiers, setting parameters for each model.\n",
        "classifiers = [MultinomialNB(),\n",
        "               LogisticRegression(),\n",
        "               DecisionTreeClassifier(max_depth = 5),\n",
        "               AdaBoostClassifier(), \n",
        "               RandomForestClassifier(max_depth = 5, n_estimators = 10),\n",
        "               SVC(probability = True), \n",
        "               ]\n",
        "\n",
        "# Creating a dictionary to store the optimal thresholds for each model.\n",
        "thresholds = {}\n",
        "\n",
        "# Fitting each classifier to the training set, making predictions on the test set,\n",
        "# evaluating performance, and finding the optimal threshold for each model.\n",
        "for name, clf in zip(names, classifiers):\n",
        "    clf_pipe = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_df = 0.9, max_features = 5000,\n",
        "                                  min_df = 0.1,\n",
        "                                  use_idf = True, tokenizer = tokenize_and_stem, ngram_range = (1, 3))), \n",
        "        (name, clf)\n",
        "    ])\n",
        "  \n",
        "    clf_pipe.fit(X_train_u, y_train_u)\n",
        "\n",
        "    pred_prob = clf_pipe.predict_proba(X_test_u)[:, 1]\n",
        "    fpr, tpr, thresholds_ = roc_curve(y_test_u, pred_prob)\n",
        "\n",
        "    # Computing the G-mean for each threshold.\n",
        "    g_mean = []\n",
        "    for thresh in thresholds_:\n",
        "        pred = (pred_prob >= thresh).astype(int)\n",
        "        g_mean.append(geometric_mean_score(y_test_u, pred))\n",
        "\n",
        "    # Choosing the threshold that maximizes the G-mean.\n",
        "    optimal_idx = np.argmax(g_mean)\n",
        "    optimal_threshold = thresholds_[optimal_idx]\n",
        "\n",
        "    # Storing the optimal threshold in the dictionary.\n",
        "    thresholds[name] = optimal_threshold\n",
        "\n",
        "    # Making predictions using the optimal threshold.\n",
        "    pred = (pred_prob >= optimal_threshold).astype(int)\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test_u, pred_prob)\n",
        "    log_loss_val = log_loss(y_test_u, pred_prob)\n",
        "    g_mean_val = geometric_mean_score(y_test_u, pred)\n",
        "\n",
        "    target_names = ['Not counterfeit product', 'Counterfeit product']\n",
        "\n",
        "    print('\\n\\n', name, '\\n\\n')\n",
        "    print(classification_report(y_test_u, pred, target_names = target_names))\n",
        "    print('ROC AUC: ', round(roc_auc, 2))\n",
        "    print('Log loss: ', round(log_loss_val, 2))\n",
        "    print('G-mean: ', round(g_mean_val, 2))\n",
        "    print('Optimal threshold: ', round(optimal_threshold, 2))\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIJyyKAiV2Xm",
        "outputId": "eadd6698-0e9f-48f5-e1d1-48d6b7376043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Naive Bayes \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       1.00      0.65      0.78       345\n",
            "    Counterfeit product       0.13      0.95      0.23        19\n",
            "\n",
            "               accuracy                           0.66       364\n",
            "              macro avg       0.56      0.80      0.51       364\n",
            "           weighted avg       0.95      0.66      0.75       364\n",
            "\n",
            "ROC AUC:  0.86\n",
            "Log loss:  0.16\n",
            "G-mean:  0.78\n",
            "Optimal threshold:  0.06\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Logistic Regression \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.98      0.82      0.89       345\n",
            "    Counterfeit product       0.18      0.74      0.29        19\n",
            "\n",
            "               accuracy                           0.82       364\n",
            "              macro avg       0.58      0.78      0.59       364\n",
            "           weighted avg       0.94      0.82      0.86       364\n",
            "\n",
            "ROC AUC:  0.87\n",
            "Log loss:  0.16\n",
            "G-mean:  0.78\n",
            "Optimal threshold:  0.07\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Decision Tree \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.98      0.90      0.94       345\n",
            "    Counterfeit product       0.26      0.63      0.37        19\n",
            "\n",
            "               accuracy                           0.89       364\n",
            "              macro avg       0.62      0.77      0.65       364\n",
            "           weighted avg       0.94      0.89      0.91       364\n",
            "\n",
            "ROC AUC:  0.76\n",
            "Log loss:  0.45\n",
            "G-mean:  0.75\n",
            "Optimal threshold:  0.2\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Boosted Tree \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.99      0.77      0.86       345\n",
            "    Counterfeit product       0.17      0.84      0.28        19\n",
            "\n",
            "               accuracy                           0.77       364\n",
            "              macro avg       0.58      0.81      0.57       364\n",
            "           weighted avg       0.95      0.77      0.83       364\n",
            "\n",
            "ROC AUC:  0.84\n",
            "Log loss:  0.52\n",
            "G-mean:  0.8\n",
            "Optimal threshold:  0.49\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Random Forest \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.98      0.84      0.91       345\n",
            "    Counterfeit product       0.19      0.68      0.30        19\n",
            "\n",
            "               accuracy                           0.84       364\n",
            "              macro avg       0.59      0.76      0.60       364\n",
            "           weighted avg       0.94      0.84      0.88       364\n",
            "\n",
            "ROC AUC:  0.85\n",
            "Log loss:  0.16\n",
            "G-mean:  0.76\n",
            "Optimal threshold:  0.07\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " SVM \n",
            "\n",
            "\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.99      0.63      0.77       345\n",
            "    Counterfeit product       0.12      0.89      0.21        19\n",
            "\n",
            "               accuracy                           0.64       364\n",
            "              macro avg       0.55      0.76      0.49       364\n",
            "           weighted avg       0.95      0.64      0.74       364\n",
            "\n",
            "ROC AUC:  0.79\n",
            "Log loss:  0.19\n",
            "G-mean:  0.75\n",
            "Optimal threshold:  0.06\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Builsequential model with sentence embedding (300 dimensions).\n",
        "# Pre-processing reviews for modeling.\n",
        "vocab_size = 5000\n",
        "embedding_dim = 300\n",
        "max_length = 500\n",
        "trunc_type ='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(X_train_u)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(X_train_u)\n",
        "testing_sequences = tokenizer.texts_to_sequences(X_test_u)\n",
        "\n",
        "# Padding\n",
        "padded = pad_sequences(sequences, maxlen = max_length, truncating = trunc_type) \n",
        "testing_padded = pad_sequences(testing_sequences, maxlen = max_length)  "
      ],
      "metadata": {
        "id": "0x5YaZHOkHhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a 2-layer (100, 100) fully-connected neural network model using review length 500 and 300-dimension.\n",
        "# Using activation ='softmax', loss ='categorical_crossentropy'\n",
        "model_500_300_u = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation ='relu'),\n",
        "    tf.keras.layers.Dense(100, activation ='relu'),\n",
        "    tf.keras.layers.Dense(1, activation ='sigmoid')\n",
        "])\n",
        "model_500_300_u.compile(loss ='binary_crossentropy', optimizer ='adam', metrics = [tf.keras.metrics.AUC(name = 'roc_auc')])\n",
        "model_500_300_u.summary()"
      ],
      "metadata": {
        "id": "2p-A8Uogm-nH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20bc5d6c-97e6-4e71-a60b-e8765413ec5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 300)          1500000   \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 150000)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               15000100  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,510,301\n",
            "Trainable params: 16,510,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model.\n",
        "num_epochs = 100\n",
        "history = model_500_300_u.fit(padded, y_train_u, epochs = num_epochs, validation_data = (testing_padded, y_test_u))"
      ],
      "metadata": {
        "id": "-YxIQsfTm-xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbce718e-3f52-40c1-e473-30676e9db83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 4s 140ms/step - loss: 0.2745 - roc_auc: 0.5565 - val_loss: 0.1917 - val_roc_auc: 0.8661\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 3s 138ms/step - loss: 0.1891 - roc_auc: 0.7782 - val_loss: 0.1451 - val_roc_auc: 0.9442\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 4s 153ms/step - loss: 0.0871 - roc_auc: 0.9799 - val_loss: 0.0896 - val_roc_auc: 0.9783\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 3s 139ms/step - loss: 0.0360 - roc_auc: 0.9982 - val_loss: 0.0692 - val_roc_auc: 0.9795\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 0.0152 - roc_auc: 0.9998 - val_loss: 0.0721 - val_roc_auc: 0.9833\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 0.0038 - roc_auc: 1.0000 - val_loss: 0.0646 - val_roc_auc: 0.9780\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 4s 149ms/step - loss: 0.0018 - roc_auc: 1.0000 - val_loss: 0.0750 - val_roc_auc: 0.9615\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 8.3233e-04 - roc_auc: 1.0000 - val_loss: 0.0902 - val_roc_auc: 0.9399\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 5.5164e-04 - roc_auc: 1.0000 - val_loss: 0.0812 - val_roc_auc: 0.9394\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 4.0159e-04 - roc_auc: 1.0000 - val_loss: 0.0839 - val_roc_auc: 0.9400\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 4s 146ms/step - loss: 3.0695e-04 - roc_auc: 1.0000 - val_loss: 0.0885 - val_roc_auc: 0.9402\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 2.3221e-04 - roc_auc: 1.0000 - val_loss: 0.0874 - val_roc_auc: 0.9402\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 1.9849e-04 - roc_auc: 1.0000 - val_loss: 0.0878 - val_roc_auc: 0.9405\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 3s 144ms/step - loss: 1.6776e-04 - roc_auc: 1.0000 - val_loss: 0.0934 - val_roc_auc: 0.9411\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 1.4128e-04 - roc_auc: 1.0000 - val_loss: 0.0894 - val_roc_auc: 0.9409\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 3s 138ms/step - loss: 1.2411e-04 - roc_auc: 1.0000 - val_loss: 0.0917 - val_roc_auc: 0.9411\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 1.0951e-04 - roc_auc: 1.0000 - val_loss: 0.0920 - val_roc_auc: 0.9413\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 3s 145ms/step - loss: 9.6640e-05 - roc_auc: 1.0000 - val_loss: 0.0933 - val_roc_auc: 0.9416\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 3s 131ms/step - loss: 8.7335e-05 - roc_auc: 1.0000 - val_loss: 0.0942 - val_roc_auc: 0.9417\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 3s 138ms/step - loss: 7.7551e-05 - roc_auc: 1.0000 - val_loss: 0.0931 - val_roc_auc: 0.9416\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 3s 140ms/step - loss: 6.9622e-05 - roc_auc: 1.0000 - val_loss: 0.0927 - val_roc_auc: 0.9416\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 3s 139ms/step - loss: 6.2496e-05 - roc_auc: 1.0000 - val_loss: 0.0945 - val_roc_auc: 0.9422\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 5.7538e-05 - roc_auc: 1.0000 - val_loss: 0.0981 - val_roc_auc: 0.9422\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 5.2064e-05 - roc_auc: 1.0000 - val_loss: 0.0954 - val_roc_auc: 0.9423\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 4s 150ms/step - loss: 4.7561e-05 - roc_auc: 1.0000 - val_loss: 0.0961 - val_roc_auc: 0.9422\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 4.3790e-05 - roc_auc: 1.0000 - val_loss: 0.0972 - val_roc_auc: 0.9422\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 4.0843e-05 - roc_auc: 1.0000 - val_loss: 0.0978 - val_roc_auc: 0.9422\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 3s 130ms/step - loss: 3.7795e-05 - roc_auc: 1.0000 - val_loss: 0.0975 - val_roc_auc: 0.9422\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 4s 148ms/step - loss: 3.5447e-05 - roc_auc: 1.0000 - val_loss: 0.1010 - val_roc_auc: 0.9425\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 3.2599e-05 - roc_auc: 1.0000 - val_loss: 0.0978 - val_roc_auc: 0.9422\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 3.0322e-05 - roc_auc: 1.0000 - val_loss: 0.0983 - val_roc_auc: 0.9422\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 4s 158ms/step - loss: 2.8402e-05 - roc_auc: 1.0000 - val_loss: 0.1002 - val_roc_auc: 0.9425\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 3s 130ms/step - loss: 2.7532e-05 - roc_auc: 1.0000 - val_loss: 0.0980 - val_roc_auc: 0.9422\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 2.4967e-05 - roc_auc: 1.0000 - val_loss: 0.1008 - val_roc_auc: 0.9423\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 2.3349e-05 - roc_auc: 1.0000 - val_loss: 0.1011 - val_roc_auc: 0.9425\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 4s 150ms/step - loss: 2.2103e-05 - roc_auc: 1.0000 - val_loss: 0.1007 - val_roc_auc: 0.9423\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 2.0868e-05 - roc_auc: 1.0000 - val_loss: 0.1017 - val_roc_auc: 0.9426\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 2.1177e-05 - roc_auc: 1.0000 - val_loss: 0.1102 - val_roc_auc: 0.9426\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 3s 147ms/step - loss: 1.8547e-05 - roc_auc: 1.0000 - val_loss: 0.1051 - val_roc_auc: 0.9428\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.7242e-05 - roc_auc: 1.0000 - val_loss: 0.1017 - val_roc_auc: 0.9426\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.6139e-05 - roc_auc: 1.0000 - val_loss: 0.0995 - val_roc_auc: 0.9425\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.5346e-05 - roc_auc: 1.0000 - val_loss: 0.1010 - val_roc_auc: 0.9426\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 4s 151ms/step - loss: 1.4598e-05 - roc_auc: 1.0000 - val_loss: 0.1018 - val_roc_auc: 0.9426\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.3937e-05 - roc_auc: 1.0000 - val_loss: 0.1021 - val_roc_auc: 0.9426\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 1.3547e-05 - roc_auc: 1.0000 - val_loss: 0.0957 - val_roc_auc: 0.9426\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 1.2812e-05 - roc_auc: 1.0000 - val_loss: 0.0986 - val_roc_auc: 0.9422\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 3s 142ms/step - loss: 1.1917e-05 - roc_auc: 1.0000 - val_loss: 0.1017 - val_roc_auc: 0.9427\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 1.1203e-05 - roc_auc: 1.0000 - val_loss: 0.1032 - val_roc_auc: 0.9427\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 1.0756e-05 - roc_auc: 1.0000 - val_loss: 0.1037 - val_roc_auc: 0.9428\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 4s 150ms/step - loss: 1.0267e-05 - roc_auc: 1.0000 - val_loss: 0.1042 - val_roc_auc: 0.9428\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 9.9553e-06 - roc_auc: 1.0000 - val_loss: 0.1059 - val_roc_auc: 0.9423\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 9.4738e-06 - roc_auc: 1.0000 - val_loss: 0.1043 - val_roc_auc: 0.9428\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 9.1000e-06 - roc_auc: 1.0000 - val_loss: 0.1048 - val_roc_auc: 0.9428\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 4s 149ms/step - loss: 8.7920e-06 - roc_auc: 1.0000 - val_loss: 0.1051 - val_roc_auc: 0.9428\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 8.4362e-06 - roc_auc: 1.0000 - val_loss: 0.1061 - val_roc_auc: 0.9425\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 8.1415e-06 - roc_auc: 1.0000 - val_loss: 0.1063 - val_roc_auc: 0.9425\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 4s 148ms/step - loss: 7.8532e-06 - roc_auc: 1.0000 - val_loss: 0.1069 - val_roc_auc: 0.9425\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 7.5377e-06 - roc_auc: 1.0000 - val_loss: 0.1069 - val_roc_auc: 0.9425\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 7.3121e-06 - roc_auc: 1.0000 - val_loss: 0.1063 - val_roc_auc: 0.9425\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 7.0332e-06 - roc_auc: 1.0000 - val_loss: 0.1065 - val_roc_auc: 0.9425\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 4s 150ms/step - loss: 6.8318e-06 - roc_auc: 1.0000 - val_loss: 0.1045 - val_roc_auc: 0.9428\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 6.5126e-06 - roc_auc: 1.0000 - val_loss: 0.1057 - val_roc_auc: 0.9425\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 6.2767e-06 - roc_auc: 1.0000 - val_loss: 0.1067 - val_roc_auc: 0.9425\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 3s 143ms/step - loss: 6.0781e-06 - roc_auc: 1.0000 - val_loss: 0.1071 - val_roc_auc: 0.9426\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 3s 139ms/step - loss: 5.8751e-06 - roc_auc: 1.0000 - val_loss: 0.1074 - val_roc_auc: 0.9426\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 5.6207e-06 - roc_auc: 1.0000 - val_loss: 0.1077 - val_roc_auc: 0.9426\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 5.3376e-06 - roc_auc: 1.0000 - val_loss: 0.1068 - val_roc_auc: 0.9426\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 4s 156ms/step - loss: 4.9890e-06 - roc_auc: 1.0000 - val_loss: 0.1072 - val_roc_auc: 0.9426\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 3s 138ms/step - loss: 4.5601e-06 - roc_auc: 1.0000 - val_loss: 0.1074 - val_roc_auc: 0.9426\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 3s 137ms/step - loss: 4.0963e-06 - roc_auc: 1.0000 - val_loss: 0.1058 - val_roc_auc: 0.9426\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 3s 144ms/step - loss: 3.5975e-06 - roc_auc: 1.0000 - val_loss: 0.1071 - val_roc_auc: 0.9426\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 3s 141ms/step - loss: 3.1590e-06 - roc_auc: 1.0000 - val_loss: 0.1070 - val_roc_auc: 0.9426\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 2.7825e-06 - roc_auc: 1.0000 - val_loss: 0.1064 - val_roc_auc: 0.9426\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 3s 131ms/step - loss: 2.4570e-06 - roc_auc: 1.0000 - val_loss: 0.1074 - val_roc_auc: 0.9428\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 4s 152ms/step - loss: 2.1368e-06 - roc_auc: 1.0000 - val_loss: 0.1076 - val_roc_auc: 0.9428\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.9351e-06 - roc_auc: 1.0000 - val_loss: 0.1077 - val_roc_auc: 0.9431\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 1.7524e-06 - roc_auc: 1.0000 - val_loss: 0.1096 - val_roc_auc: 0.9175\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 3s 140ms/step - loss: 1.5445e-06 - roc_auc: 1.0000 - val_loss: 0.1088 - val_roc_auc: 0.9172\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 4s 147ms/step - loss: 1.4053e-06 - roc_auc: 1.0000 - val_loss: 0.1091 - val_roc_auc: 0.9172\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.2855e-06 - roc_auc: 1.0000 - val_loss: 0.1090 - val_roc_auc: 0.9172\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 3s 131ms/step - loss: 1.1867e-06 - roc_auc: 1.0000 - val_loss: 0.1097 - val_roc_auc: 0.9175\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 4s 150ms/step - loss: 1.1011e-06 - roc_auc: 1.0000 - val_loss: 0.1100 - val_roc_auc: 0.9175\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 1.0142e-06 - roc_auc: 1.0000 - val_loss: 0.1110 - val_roc_auc: 0.9175\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 9.4411e-07 - roc_auc: 1.0000 - val_loss: 0.1115 - val_roc_auc: 0.9175\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 3s 137ms/step - loss: 8.7800e-07 - roc_auc: 1.0000 - val_loss: 0.1108 - val_roc_auc: 0.9175\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 4s 150ms/step - loss: 8.2572e-07 - roc_auc: 1.0000 - val_loss: 0.1112 - val_roc_auc: 0.9175\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 7.7710e-07 - roc_auc: 1.0000 - val_loss: 0.1110 - val_roc_auc: 0.9175\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 3s 137ms/step - loss: 7.2894e-07 - roc_auc: 1.0000 - val_loss: 0.1127 - val_roc_auc: 0.9175\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 4s 148ms/step - loss: 6.8934e-07 - roc_auc: 1.0000 - val_loss: 0.1124 - val_roc_auc: 0.9175\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 6.5398e-07 - roc_auc: 1.0000 - val_loss: 0.1135 - val_roc_auc: 0.9175\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 6.2052e-07 - roc_auc: 1.0000 - val_loss: 0.1124 - val_roc_auc: 0.9175\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 3s 132ms/step - loss: 5.8351e-07 - roc_auc: 1.0000 - val_loss: 0.1135 - val_roc_auc: 0.9175\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 4s 152ms/step - loss: 5.5922e-07 - roc_auc: 1.0000 - val_loss: 0.1147 - val_roc_auc: 0.9178\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 5.2858e-07 - roc_auc: 1.0000 - val_loss: 0.1141 - val_roc_auc: 0.9175\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 5.0557e-07 - roc_auc: 1.0000 - val_loss: 0.1151 - val_roc_auc: 0.9178\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 3s 142ms/step - loss: 4.8193e-07 - roc_auc: 1.0000 - val_loss: 0.1149 - val_roc_auc: 0.9178\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 3s 136ms/step - loss: 4.6005e-07 - roc_auc: 1.0000 - val_loss: 0.1141 - val_roc_auc: 0.9175\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 3s 130ms/step - loss: 4.4179e-07 - roc_auc: 1.0000 - val_loss: 0.1157 - val_roc_auc: 0.9178\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 3s 135ms/step - loss: 4.2343e-07 - roc_auc: 1.0000 - val_loss: 0.1158 - val_roc_auc: 0.9178\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 4s 149ms/step - loss: 4.0334e-07 - roc_auc: 1.0000 - val_loss: 0.1156 - val_roc_auc: 0.9178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding optimal threshold and evaluating the model.\n",
        "y_pred_proba_u = model_500_300_u.predict(testing_padded)\n",
        "y_pred_proba_u = y_pred_proba_u[:, 0]\n",
        "fpr, tpr, thresholds = roc_curve(y_test_u, y_pred_proba_u)\n",
        "sort_idx = np.argsort(thresholds)\n",
        "fpr = fpr[sort_idx]\n",
        "tpr = tpr[sort_idx]\n",
        "thresholds = thresholds[sort_idx]\n",
        "gmeans_ker = np.sqrt(tpr * (1-fpr))\n",
        "gmeans_ker[np.isnan(gmeans_ker)] = 0\n",
        "optimal_idx = np.argmax(gmeans_ker)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "y_pred = (y_pred_proba_u >= optimal_threshold).astype(int)\n",
        "\n",
        "log_loss_val = log_loss(y_test_u, y_pred_proba_u)\n",
        "\n",
        "print(classification_report(y_test_u, y_pred, target_names = target_names))\n",
        "print('ROC AUC: ', round(auc(fpr, tpr), 2))\n",
        "print(\"Optimal Threshold:\", round(optimal_threshold, 5))\n",
        "print('Log loss: ', round(log_loss_val, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cds_qvskZlnm",
        "outputId": "aa357c80-a130-49e7-e46a-6843ee066782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 18ms/step\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.99      0.97      0.98       345\n",
            "    Counterfeit product       0.65      0.89      0.76        19\n",
            "\n",
            "               accuracy                           0.97       364\n",
            "              macro avg       0.82      0.93      0.87       364\n",
            "           weighted avg       0.98      0.97      0.97       364\n",
            "\n",
            "ROC AUC:  0.98\n",
            "Optimal Threshold: 0.0031\n",
            "Log loss:  0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model.\n",
        "# y_pred_u = model_500_300_o.predict(testing_padded)\n",
        "# y_pred_u = (y_pred_u >= 0.5)\n",
        "\n",
        "# fpr, tpr, thresholds = roc_curve(y_test_u, y_pred_u)\n",
        "# log_loss_val = log_loss(y_test_u, y_pred_u)\n",
        "\n",
        "# print(classification_report(y_test_u, y_pred_u, target_names = target_names))\n",
        "# print('ROC AUC: ', round(auc(fpr, tpr), 2))\n",
        "# print('Log loss: ', round(log_loss_val, 2))"
      ],
      "metadata": {
        "id": "CCGKush7oE9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acafa73-52d1-4b3f-9708-38f3df3e15ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 1s 55ms/step\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Not counterfeit product       0.95      1.00      0.97       345\n",
            "    Counterfeit product       0.00      0.00      0.00        19\n",
            "\n",
            "               accuracy                           0.95       364\n",
            "              macro avg       0.47      0.50      0.49       364\n",
            "           weighted avg       0.90      0.95      0.92       364\n",
            "\n",
            "ROC AUC:  0.5\n",
            "Log loss:  1.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy, Precision, Recall, and F-measure are threshold-dependent metrics. ROC curve and AUC are threshold-independent. G-means were used to find an optimal threshold. \n",
        "- ROC AUC:\n",
        "     - Naive Bayes: 0.86\n",
        "     - Logistic Regression: 0.87\n",
        "     - Decision Tree: 0.76\n",
        "     - Boosted Tree: 0.84\n",
        "     - Random Forest: 0.85\n",
        "     - SVM: 0.79\n",
        "     - Keras: 0.98\n",
        "\n",
        "Keras model has the best performance based on ROC AUC metric of 0.98 and optimal threshold of 0.0031.\n",
        "\n",
        "Logistic Regression has the second best performance based on ROC AUC metric of 0.87 and optimal threshold of 0.07."
      ],
      "metadata": {
        "id": "d_hVeSroeZMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuilding Naive Bayers model.\n",
        "vectorizer = TfidfVectorizer(ngram_range = (2, 3))\n",
        "\n",
        "X_train_tfidf_u = vectorizer.fit_transform(X_train_u)\n",
        "\n",
        "selector = SelectKBest(chi2, k = 10000)\n",
        "selector.fit(X_train_tfidf_u, y_train_u)\n",
        "\n",
        "X_train_selected_u = selector.transform(X_train_tfidf_u)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_selected_u, y_train_u)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "selected_mask = selector.get_support()\n",
        "\n",
        "selected_features = [feature_names[i] for i in range(len(feature_names)) if selected_mask[i]]\n",
        "\n",
        "top_negative = np.argsort(clf.feature_log_prob_[1])[::-1][:10]\n",
        "top_positive = np.argsort(clf.feature_log_prob_[0])[::-1][:10]\n",
        "\n",
        "print(\"Top positive features:\", [selected_features[i] for i in top_positive])\n",
        "print(\"Top negative features:\", [selected_features[i] for i in top_negative])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnKyDdetCgMg",
        "outputId": "9a1cf0a9-1076-4f42-944b-c5de7723fc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top positive features: ['love boots', 'warm comfortable', 'love uggs', 'perfect fit', 'fit perfectly', 'comfortable warm', 'great product', 'good quality', 'wife loves', 'fit perfect']\n",
            "Top negative features: ['waste money', 'real uggs', 'original packaging', 'qr code', 'ugg horrible', 'horrible material', 'ugg horrible material', 'fake ugg horrible', 'poor quality', 'fake ugg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top counterfeit features:\n",
        "\n",
        "- 'waste money':\n",
        "\n",
        "This feature appears in 1 review:\n",
        "\n",
        "     - thin leather - hole in front of boot and have only had them 6 months - will not waste money again - last pair of UGGS lasted 6 years very disappointing!!!\n",
        "\n",
        "- 'real uggs':\n",
        "\n",
        "This feature appears in 5 review:\n",
        "\n",
        "     - My husband ordered these for me for Christmas. I'm happy he showed them to me before wrapping them because they were definitely NOT real Uggs. Felt cheap and didnt have the same trademarking as my other pair of Uggs that we got from an actual Ugg store. He returned them and ordered from the Ugg website.\n",
        "     - My mom purchased these for me as a gift. Upon opening them I found the material to be quite flimsy. I also noticed that the boot had some seams in weird places. The fur was not typical for the brand (I have had Uggs before)... I checked the boot over and noticed it was missing the circle R for registered trademark. Real Uggs have that. These boots did not. I did call around to verify that this the circle R was essential for true Uggs. Left is fake and right is real.\n",
        "\n",
        "- 'month already':\n",
        "\n",
        "This feature as two words did not appears in any reviews. However,\n",
        "the words 'month' and 'already' appear in 5 reviews:\n",
        "\n",
        "     - Wife loved these boots. Unfortunately the seam on the outside of the ankle only lasted a month of casual use. She's had pairs of this boot in the past that wore well so I don't know where the build quality went.\n",
        "     - Only have had them for two months and they already ripped through the big toe.\n",
        "     - Bought these in December 2022 and maybe worn 6 times. Noticed today they have a hole in the seam already. For UGGs I would not have expected that to happen. Especially for $200. I was super happy with them until I found this today. Of course the return window has closed.\n",
        "     - These were obviously fake. The label was wrong, the sole was wrong, and they fit waaaay too small and narrow. I bought them to replace an authentic pair I already owned. I compared them side by side and these were a knockoff. Do yourself a favor and save the headache of having to return them, do not buy these. Buy directly from Ugg.\n",
        "\n",
        "- 'original packaging':\n",
        "\n",
        "This feature appears in 1 review:\n",
        "\n",
        "     - Did not like that the item was shipped without the original packaging.\n",
        "\n",
        "- 'ugg horrible', 'ugg horrible material', 'horrible material':\n",
        "\n",
        "The 'horrible material' features appears as two words together in 1 review:\n",
        "\n",
        "     - fake uggâ€™s horrible material!!\n",
        "\n",
        "However, the word 'material' appears in 9 reviews:\n",
        "\n",
        "     - Inner vertical seam came a part due to poor quality, lack of material overlap. Was only able to wear twice.\n",
        "     - These shoes are not real UGGs. You can tell  from the inside material and the Â® from the logo.\n",
        "     - The material wasnâ€™t as described. Fake Fur. Rough synthetic unfinished in the inside. Returned.\n",
        "\n",
        "- 'fake ugg horrible':\n",
        "\n",
        "This feature as itself did not appears in any review. However, 'fake ugg' appears in 8 reviews:\n",
        "\n",
        "     - These boots are fake UGGs.  They did arrive in a new box marked with UGG on it as well as inside paper that says \"UGG\" all over it.  However, they looked fake, smelled fake, felt fake and the faux fur on the inside was not even soft.  Just Yuck!!!\n",
        "     - Boots arrived in UGG box and appeared to be genuine, but are not. These are fake UGGs that appear identical but are not the same. The way I was able to identify this was because the \"UGG\" logo on the bottom of the boot did not have the trademark logo and they are flimsy and cheap feeling. Returning these for my money back, don't order these! I am reporting this to Amazon and reaching out to UGG directly.\n",
        "     - These were fake Uggâ€™s at the real ugg price.  The ugg label was missing the registered trademark symbol.  Uggâ€™s is a registered name and always has that.  I was disappointed and sent them back. Donâ€™t buy. None of the ugg guarantee info was included either.\n",
        "\n",
        "- 'qr code':\n",
        "\n",
        "This feature appears in 4 review:\n",
        "\n",
        "     - I am pretty shocked that this UGG classic long boot is fake.  I have an original one purchased from Nordstrom.  The QR code tag is different and the inner lining is low quality.  Be careful. I am returning this fake UGG today.\n",
        "     - Found a lot of differences in craftsmanship, packaging, and quality. Pretty shocking differences actually. Either this amazon pair is 100% real fugazi or they're QC reject/RTV outlet bound real pairs. The QR code on the amazon purchased pair did not work. The QR code on the pair from the manufacturer store works as intended. Be careful yall. Your chick is gonna be pissed if she ends up with a pair of OOG's\n",
        "     - These Ugg boots are not Authentic at all. They are missing the QR Code inside, The stitching around the label is weird and they fit tight. I have 8 pairs of Ugg boots and none of them are like these! I'm so disappointed!\n",
        "\n",
        "- 'real one':\n",
        "\n",
        "This feature appears in 3 review:\n",
        "\n",
        "     - These are fake, didnâ€™t realize till I bought ones from the store Iâ€™ll attach pictures just buy them from the website or store not worth the two day shipping barely held up had them less then a year uggs I bought at the store have lasted me 2 winters before getting unwearable You can tell in the little things fur on the inside is not as soft/ got matted, authentic tag is lower down on the real ones, height difference (even when I straighten the slouched old one it does not equal height) Purchase at ur own risk !!! They are great fakes Iâ€™ve been wearing uggs for years and didnâ€™t notice till I got my fresh new pair!!\n",
        "     - ITEM IS FAKE. it's a good fake, but when you have a real one beside it it's obvious..  poor stitching, fake leather, the mold for the sole has the sun wrong, lettering is blurry, real ones are a darker black.. FAKE FAKE FAKE.\n"
      ],
      "metadata": {
        "id": "hF1cMe1EDws7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# Creating an explainer object for the best model (Keras).\n",
        "explainer_u = shap.Explainer(model_500_300_u, testing_padded)\n",
        "\n",
        "# Generating SHAP values for the testing dataset.\n",
        "shap_values_u = explainer_u(testing_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKWsUdY6q5oo",
        "outputId": "533317e3-f9c9-43bb-a9fe-a8fc08d7cd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Permutation explainer: 365it [44:57,  7.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating features by class: 0 and 1.\n",
        "# Average the SHAP values for each feature over all the reviews in each class.\n",
        "shap_values_0 = shap_values_u[y_test_u.values == 0].mean(axis=0)\n",
        "shap_values_1 = shap_values_u[y_test_u.values == 1].mean(axis=0)\n",
        "\n",
        "# Getting the feature names.\n",
        "feature_names = list(tokenizer.word_index.keys())\n",
        "\n",
        "# Convert the Explanation objects to numpy arrays\n",
        "shap_values_0_np = shap_values_0.values\n",
        "shap_values_1_np = shap_values_1.values\n",
        "\n",
        "# Sorting the features based on their average importance values.\n",
        "sorted_features_0 = [feature_names[i] for i in np.argsort(np.abs(shap_values_0_np))[::-1]]\n",
        "sorted_features_1 = [feature_names[i] for i in np.argsort(np.abs(shap_values_1_np))[::-1]]\n",
        "\n",
        "print(\"Top 20 features for non-counterfeit product (0):\")\n",
        "for feature in sorted_features_0[:20]:\n",
        "    print(feature)\n",
        "print()\n",
        "\n",
        "print(\"Top 20 features for counterfeit product (1):\")\n",
        "for feature in sorted_features_1[:20]:\n",
        "    print(feature)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wwK5XcWxhEa",
        "outputId": "7b1afcab-94f6-4f4d-a9c6-5fabb89bf08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 features for non-counterfeit product (0):\n",
            "stars\n",
            "em\n",
            "possible\n",
            "customer\n",
            "shearling\n",
            "anyone\n",
            "labels\n",
            "everyone\n",
            "page\n",
            "legit\n",
            "sign\n",
            "chestnut\n",
            "australia\n",
            "prefer\n",
            "number\n",
            "ice\n",
            "official\n",
            "stains\n",
            "stated\n",
            "three\n",
            "\n",
            "Top 20 features for counterfeit product (1):\n",
            "stars\n",
            "possible\n",
            "customer\n",
            "anyone\n",
            "shearling\n",
            "em\n",
            "chestnut\n",
            "legit\n",
            "page\n",
            "ice\n",
            "labels\n",
            "sign\n",
            "prefer\n",
            "australia\n",
            "number\n",
            "everyone\n",
            "gonna\n",
            "official\n",
            "three\n",
            "you’re\n",
            "\n"
          ]
        }
      ]
    }
  ]
}