{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Scrape at least 400 full reviews and ratings from Yelp for a restaurant that has mixed reviews. "
      ],
      "metadata": {
        "id": "GyVFk-yWiRYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recode the ratings. 1-3 = Negative, 4-5 = Positive. \n"
      ],
      "metadata": {
        "id": "XRWKQ2GpfKzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "gosmans = pd.read_csv('gosmans.csv')"
      ],
      "metadata": {
        "id": "RLgrQxDvuMRy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recoding to 1 and 0 oppose to 'pos' and 'neg' so I can feed the roc_auc when reporting metrics\n",
        "\n",
        "def recoder(values):\n",
        "  if values >3:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "Nnvt8RNEa-GB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gosmans['rating'] = gosmans['rating'].apply(recoder)"
      ],
      "metadata": {
        "id": "H023VBO1bZoO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean and pre-process the data (remove punctuation, convert all words to lower case, remove stopwords, lemmatize the corpus).\n"
      ],
      "metadata": {
        "id": "O0eMkzQJiYq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "3sEiTWkQzZL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3104dfd-ccda-44df-b2b4-267451cdfecf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA90hGCfwg7L",
        "outputId": "857980e0-0e18-492e-fe2f-ebc652d1c708"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gosmans['review_text'] = gosmans['review_text'].str.lower()"
      ],
      "metadata": {
        "id": "Wm6RvW1Fye0n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gosmans['review_text'] = gosmans['review_text'].str.split()"
      ],
      "metadata": {
        "id": "BQKn7C7LytPV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def punctuation(words):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "cl9bd93b0JwO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gosmans['review_text'] = gosmans['review_text'].apply(punctuation)"
      ],
      "metadata": {
        "id": "kFZbvTO70LUD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop(words):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "DPDSqTqNy90u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gosmans['review_text'] = gosmans['review_text'].apply(remove_stop)"
      ],
      "metadata": {
        "id": "4vrprvgejsoR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def join_string(list_string):\n",
        "    string = ','.join(list_string)\n",
        "    return string"
      ],
      "metadata": {
        "id": "q6MUBYFc28us"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gosmans['review_text'] = gosmans['review_text'].apply(join_string)"
      ],
      "metadata": {
        "id": "siss_OjA3BP0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "gosmans['review_text'] = [wordnet_lemmatizer.lemmatize(word) for word in gosmans['review_text']]"
      ],
      "metadata": {
        "id": "3mgGeWiEvsdB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Build count vectorized feature representation for the reviews (hint: sklearn.feature_extraction.text.countvectorizer). (2 pts.)\n"
      ],
      "metadata": {
        "id": "MyJXtnDSfQmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Develop the NB, LR, DT, BT, RF, SVM, and ANN classifiers to predict review sentiment. Evaluate average recall, precision, F1, ROC AUC, and PR AUC for each model. (12 pts.)"
      ],
      "metadata": {
        "id": "fLSNz9b0zAQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = gosmans['review_text']\n",
        "y = gosmans['rating']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "q0kC-EiBfms_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Develop the NB, LR, DT, BT, RF, SVM, and ANN classifiers to predict review sentiment. Evaluate average recall, precision, F1, ROC AUC, and PR AUC for each model. (12 pts.)"
      ],
      "metadata": {
        "id": "mqihmhxifVIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score, roc_curve, auc, precision_recall_curve\n",
        "\n",
        "names = [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Neural Net\", \n",
        "         \"Naive Bayes\"]\n",
        "\n",
        "classifiers = [LogisticRegression(),\n",
        "               SVC(probability=True),\n",
        "               DecisionTreeClassifier(max_depth=5),\n",
        "               RandomForestClassifier(max_depth=5, n_estimators=10),\n",
        "               AdaBoostClassifier(),\n",
        "               MLPClassifier(alpha=1, max_iter=1000),\n",
        "               MultinomialNB()\n",
        "               ]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  clf_pipe = Pipeline([\n",
        "                    ('count', CountVectorizer()), \n",
        "                    (name, clf), \n",
        "                    ])\n",
        "  \n",
        "  clf_pipe.fit(X_train,y_train)\n",
        "\n",
        "  pred = clf_pipe.predict(X_test)\n",
        "  pred_prob = clf_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, pred_prob)\n",
        "  precision, recall, thresholds_pr = precision_recall_curve(y_test, pred)\n",
        "\n",
        "  print('\\n\\n', name, '\\n\\n')\n",
        "  print(classification_report(y_test, pred))\n",
        "  print('ROC AUC: ', auc(fpr, tpr))\n",
        "  print('Precision/Recall AUC: ', auc(precision, recall))\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "id": "9njL-InkfnbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4df433-3b49-4f43-b77e-d67f0fee8dbf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Logistic Regression \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80        68\n",
            "           1       0.74      0.84      0.79        57\n",
            "\n",
            "    accuracy                           0.79       125\n",
            "   macro avg       0.79      0.80      0.79       125\n",
            "weighted avg       0.80      0.79      0.79       125\n",
            "\n",
            "ROC AUC:  0.8913828689370484\n",
            "Precision/Recall AUC:  0.37028340080971656\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " SVM \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.72      0.79        68\n",
            "           1       0.72      0.88      0.79        57\n",
            "\n",
            "    accuracy                           0.79       125\n",
            "   macro avg       0.80      0.80      0.79       125\n",
            "weighted avg       0.81      0.79      0.79       125\n",
            "\n",
            "ROC AUC:  0.9064757481940144\n",
            "Precision/Recall AUC:  0.3729153318077803\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Decision Tree \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.81      0.72        68\n",
            "           1       0.68      0.47      0.56        57\n",
            "\n",
            "    accuracy                           0.66       125\n",
            "   macro avg       0.66      0.64      0.64       125\n",
            "weighted avg       0.66      0.66      0.64       125\n",
            "\n",
            "ROC AUC:  0.7199432404540763\n",
            "Precision/Recall AUC:  0.23834210526315788\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Random Forest \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.54      0.65        68\n",
            "           1       0.61      0.86      0.72        57\n",
            "\n",
            "    accuracy                           0.69       125\n",
            "   macro avg       0.72      0.70      0.69       125\n",
            "weighted avg       0.73      0.69      0.68       125\n",
            "\n",
            "ROC AUC:  0.791279669762642\n",
            "Precision/Recall AUC:  0.31207456140350875\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AdaBoost \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.72      0.77        68\n",
            "           1       0.71      0.81      0.75        57\n",
            "\n",
            "    accuracy                           0.76       125\n",
            "   macro avg       0.76      0.76      0.76       125\n",
            "weighted avg       0.77      0.76      0.76       125\n",
            "\n",
            "ROC AUC:  0.8317853457172343\n",
            "Precision/Recall AUC:  0.34535492577597837\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Neural Net \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79        68\n",
            "           1       0.73      0.84      0.78        57\n",
            "\n",
            "    accuracy                           0.78       125\n",
            "   macro avg       0.79      0.79      0.78       125\n",
            "weighted avg       0.79      0.78      0.78       125\n",
            "\n",
            "ROC AUC:  0.8924148606811144\n",
            "Precision/Recall AUC:  0.36468899521531095\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Naive Bayes \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.78      0.82        68\n",
            "           1       0.77      0.86      0.81        57\n",
            "\n",
            "    accuracy                           0.82       125\n",
            "   macro avg       0.82      0.82      0.82       125\n",
            "weighted avg       0.82      0.82      0.82       125\n",
            "\n",
            "ROC AUC:  0.914860681114551\n",
            "Precision/Recall AUC:  0.38863706140350873\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Build TFIDF vectorized feature representation for the reviews and evaluate NB, LR, DT, BT, RF, SVM, and ANN classifiers using recall, precision, F1, ROC AUC, and PR AUC (12 pts.)"
      ],
      "metadata": {
        "id": "6b2Q8weBfYu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Neural Net\", \n",
        "         \"Naive Bayes\"]\n",
        "\n",
        "classifiers = [LogisticRegression(),\n",
        "               SVC(probability=True),\n",
        "               DecisionTreeClassifier(max_depth=5),\n",
        "               RandomForestClassifier(max_depth=5, n_estimators=10),\n",
        "               AdaBoostClassifier(),\n",
        "               MLPClassifier(alpha=1, max_iter=1000),\n",
        "               MultinomialNB()\n",
        "               ]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  clf_pipe = Pipeline([\n",
        "                    ('tfidf', TfidfVectorizer()), \n",
        "                    (name, clf), \n",
        "                    ])\n",
        "  \n",
        "  clf_pipe.fit(X_train,y_train)\n",
        "\n",
        "  pred = clf_pipe.predict(X_test)\n",
        "  pred_prob = clf_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, pred_prob)\n",
        "  precision, recall, thresholds_pr = precision_recall_curve(y_test, pred)\n",
        "\n",
        "  print('\\n\\n', name, '\\n\\n')\n",
        "  print(classification_report(y_test, pred))\n",
        "  print('ROC AUC: ', auc(fpr, tpr))\n",
        "  print('Precision/Recall AUC: ', auc(precision, recall))\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "id": "hhL__koxfoMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d079ad80-e9f8-4e5c-dfb0-46bb1f176fa6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Logistic Regression \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.76      0.80        68\n",
            "           1       0.75      0.82      0.78        57\n",
            "\n",
            "    accuracy                           0.79       125\n",
            "   macro avg       0.79      0.79      0.79       125\n",
            "weighted avg       0.80      0.79      0.79       125\n",
            "\n",
            "ROC AUC:  0.9107327141382869\n",
            "Precision/Recall AUC:  0.36929657477025896\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " SVM \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.75      0.79        68\n",
            "           1       0.73      0.82      0.78        57\n",
            "\n",
            "    accuracy                           0.78       125\n",
            "   macro avg       0.79      0.79      0.78       125\n",
            "weighted avg       0.79      0.78      0.78       125\n",
            "\n",
            "ROC AUC:  0.9076367389060886\n",
            "Precision/Recall AUC:  0.36346820175438593\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Decision Tree \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.71      0.69        68\n",
            "           1       0.62      0.58      0.60        57\n",
            "\n",
            "    accuracy                           0.65       125\n",
            "   macro avg       0.64      0.64      0.64       125\n",
            "weighted avg       0.65      0.65      0.65       125\n",
            "\n",
            "ROC AUC:  0.6335139318885448\n",
            "Precision/Recall AUC:  0.24079443892750743\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Random Forest \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.60      0.70        68\n",
            "           1       0.64      0.86      0.74        57\n",
            "\n",
            "    accuracy                           0.72       125\n",
            "   macro avg       0.74      0.73      0.72       125\n",
            "weighted avg       0.75      0.72      0.72       125\n",
            "\n",
            "ROC AUC:  0.8074045407636741\n",
            "Precision/Recall AUC:  0.3281929824561403\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AdaBoost \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.65      0.70        68\n",
            "           1       0.65      0.77      0.70        57\n",
            "\n",
            "    accuracy                           0.70       125\n",
            "   macro avg       0.71      0.71      0.70       125\n",
            "weighted avg       0.71      0.70      0.70       125\n",
            "\n",
            "ROC AUC:  0.7739938080495355\n",
            "Precision/Recall AUC:  0.30549432404540766\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Neural Net \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.81        68\n",
            "           1       0.78      0.79      0.78        57\n",
            "\n",
            "    accuracy                           0.80       125\n",
            "   macro avg       0.80      0.80      0.80       125\n",
            "weighted avg       0.80      0.80      0.80       125\n",
            "\n",
            "ROC AUC:  0.9066047471620227\n",
            "Precision/Recall AUC:  0.37466787658802175\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Naive Bayes \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.71      0.78        68\n",
            "           1       0.71      0.88      0.79        57\n",
            "\n",
            "    accuracy                           0.78       125\n",
            "   macro avg       0.79      0.79      0.78       125\n",
            "weighted avg       0.80      0.78      0.78       125\n",
            "\n",
            "ROC AUC:  0.9187306501547987\n",
            "Precision/Recall AUC:  0.3677393483709273\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Identify the best performing representation/model combination. Explain your choice of metric. (4 pts.)\n",
        "\n"
      ],
      "metadata": {
        "id": "IcWwOoaYfb86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best representation/model combination was the Term Frequency Index representation and the Naive Bayes model. The count vectroized representation coupled with the Naive Bayes produced a .914 AUC whereas the term frequency index representation produced a slightly better .918 AUC. The metric of choice is of course AUC as this tests the TPR and FPR at various thresholds giving the most reliable score."
      ],
      "metadata": {
        "id": "TWNB43I2QTfh"
      }
    }
  ]
}